<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/><title>Spark on Kubernetes tại Fossil</title><meta name="robots" content="follow, index"/><meta name="description" content="Apache Spark được chọn làm công nghệ cho Batch layer bởi khả năng xử lý một lượng lớn data cùng một lúc. Ở thiết kế ban đầu, team data chọn sử dụng Apache Spark trên AWS EMR do có sẵn và triển khai nhanh chóng. Dần dần, AWS EMR bộc lộ một số điểm hạn chế trên môi trường Production. Trong bài viết này, mình sẽ nói về tại sao và làm thế nào team Data chuyển từ Spark trên AWS EMR sang Kubernetes."/><meta property="og:url" content="https://fossil-engineering.github.io/blog/spark-on-kubernetes-at-fossil"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Fossil Engineering"/><meta property="og:description" content="Apache Spark được chọn làm công nghệ cho Batch layer bởi khả năng xử lý một lượng lớn data cùng một lúc. Ở thiết kế ban đầu, team data chọn sử dụng Apache Spark trên AWS EMR do có sẵn và triển khai nhanh chóng. Dần dần, AWS EMR bộc lộ một số điểm hạn chế trên môi trường Production. Trong bài viết này, mình sẽ nói về tại sao và làm thế nào team Data chuyển từ Spark trên AWS EMR sang Kubernetes."/><meta property="og:title" content="Spark on Kubernetes tại Fossil"/><meta property="og:image" content="https://fossil-engineering.github.io/static/img/twitter-card.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content=""/><meta name="twitter:title" content="Spark on Kubernetes tại Fossil"/><meta name="twitter:description" content="Apache Spark được chọn làm công nghệ cho Batch layer bởi khả năng xử lý một lượng lớn data cùng một lúc. Ở thiết kế ban đầu, team data chọn sử dụng Apache Spark trên AWS EMR do có sẵn và triển khai nhanh chóng. Dần dần, AWS EMR bộc lộ một số điểm hạn chế trên môi trường Production. Trong bài viết này, mình sẽ nói về tại sao và làm thế nào team Data chuyển từ Spark trên AWS EMR sang Kubernetes."/><meta name="twitter:image" content="https://fossil-engineering.github.io/static/img/twitter-card.png"/><meta property="article:published_time" content="2022-03-10T00:00:00.000Z"/><link rel="canonical" href="https://fossil-engineering.github.io/blog/spark-on-kubernetes-at-fossil"/><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://fossil-engineering.github.io/blog/spark-on-kubernetes-at-fossil"
  },
  "headline": "Spark on Kubernetes tại Fossil",
  "image": [
    {
      "@type": "ImageObject",
      "url": "https://fossil-engineering.github.io/static/img/twitter-card.png"
    }
  ],
  "datePublished": "2022-03-10T00:00:00.000Z",
  "dateModified": "2022-03-10T00:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Duyet Le"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "",
    "logo": {
      "@type": "ImageObject",
      "url": "https://fossil-engineering.github.ioundefined"
    }
  },
  "description": "Apache Spark được chọn làm công nghệ cho Batch layer bởi khả năng xử lý một lượng lớn data cùng một lúc. Ở thiết kế ban đầu, team data chọn sử dụng Apache Spark trên AWS EMR do có sẵn và triển khai nhanh chóng. Dần dần, AWS EMR bộc lộ một số điểm hạn chế trên môi trường Production. Trong bài viết này, mình sẽ nói về tại sao và làm thế nào team Data chuyển từ Spark trên AWS EMR sang Kubernetes."
}</script><meta name="next-head-count" content="19"/><link rel="apple-touch-icon" sizes="180x180" href="/static/favicons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/favicon-16x16.png"/><link rel="manifest" href="/static/favicons/site.webmanifest"/><link rel="mask-icon" href="/static/favicons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#2b5797"/><meta name="theme-color" content="#ffffff"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://rsms.me" crossorigin="anonymous"/><link rel="stylesheet" href="https://rsms.me/inter/inter.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/b80d0b8b5e8ce299.css" as="style"/><link rel="stylesheet" href="/_next/static/css/b80d0b8b5e8ce299.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-f300109d54818391.js" defer=""></script><script src="/_next/static/chunks/framework-109a728694328ca8.js" defer=""></script><script src="/_next/static/chunks/main-3d54289b1db19e6f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-af73530b3e9d1b5f.js" defer=""></script><script src="/_next/static/chunks/459-f230713b90b0f34a.js" defer=""></script><script src="/_next/static/chunks/410-5f0c6f2fa70bc464.js" defer=""></script><script src="/_next/static/chunks/620-4ffca7d07d13ee0d.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5B...slug%5D-0a1bff3ee9d6b739.js" defer=""></script><script src="/_next/static/uAv3iUABIr6Ubl_-73ex7/_buildManifest.js" defer=""></script><script src="/_next/static/uAv3iUABIr6Ubl_-73ex7/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuGKYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuFuYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body class="antialiased text-black bg-white dark:bg-gray-900 dark:text-white"><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex flex-col justify-between h-screen"><header class="flex items-center justify-between py-10"><div><a aria-label="Fossil Engineering" href="/"><div class="flex items-center justify-between"><div class="mr-3 logo"><svg xmlns="http://www.w3.org/2000/svg" width="132.393" height="25.507" xml:space="preserve"><path d="M89.751 10.925c-4.768-1.529-6.842-2.877-6.486-5.096.342-2.201 2.729-2.07 5.047-1.89 2.291.192 4.158.701 5.52 1.148.025.018.105-.004.121-.082.121-.806.559-2.943.678-3.675.018-.091-.068-.136-.113-.147C91.729.428 89.182-.052 86.137.004c-5.703.099-8.354 2.396-8.678 7.192-.191 2.799 1.748 5.893 5.777 7.227 4.029 1.334 6.904 2.087 6.486 4.57-.369 2.104-2.85 2.342-5.539 2.187-2.355-.144-4.348-.705-5.834-1.156-.107-.032-.172.021-.197.119-.111.864-.424 3.071-.531 3.849-.004.104.084.188.129.198 1.859.445 5.15 1.07 9.197 1.07 5.473 0 8.312-2.347 8.631-6.841.247-3.487-1.395-6.067-5.827-7.494zM65.068 10.925c-4.771-1.529-6.839-2.877-6.485-5.096.344-2.201 2.729-2.07 5.04-1.89 2.292.192 4.16.701 5.517 1.148.039.018.096-.004.113-.082.139-.806.566-2.943.691-3.675a.139.139 0 0 0-.111-.147C67.04.428 64.494-.052 61.454.004 55.75.103 53.101 2.4 52.766 7.196c-.188 2.8 1.753 5.896 5.774 7.23 4.024 1.334 6.898 2.086 6.494 4.567-.367 2.105-2.846 2.342-5.539 2.188-2.366-.142-4.346-.707-5.842-1.156-.096-.032-.168.021-.188.117-.11.867-.425 3.073-.53 3.853-.003.102.075.188.124.196a40.142 40.142 0 0 0 9.191 1.07c5.478 0 8.31-2.347 8.632-6.843.256-3.486-1.387-6.066-5.814-7.493zM17.998.555H1.468a.157.157 0 0 0-.162.155v23.971c0 .088.064.16.162.16H6.96a.156.156 0 0 0 .155-.16V15.71c0-.082.072-.16.162-.16h9.525c.092 0 .164-.064.164-.15v-3.708a.165.165 0 0 0-.164-.165H7.277a.16.16 0 0 1-.162-.162V4.74c0-.085.072-.16.162-.16h10.861a.154.154 0 0 0 .156-.157L18.168.711c-.012-.08-.09-.156-.17-.156zM109.023.537h-5.666c-.1 0-.16.068-.16.156v23.991c0 .084.061.149.16.149h5.666c.09 0 .154-.065.154-.149V.693a.152.152 0 0 0-.154-.156zM133.536 20.742h-9.395a.16.16 0 0 1-.158-.156L123.981.732c0-.099-.066-.161-.16-.161h-5.658a.157.157 0 0 0-.162.161v23.951c0 .084.076.147.162.147h15.186c.088 0 .164-.063.168-.147l.182-3.772c-.002-.098-.065-.169-.163-.169zM35.363.026c-7.436 0-11.493 4.878-11.493 12.743 0 7.857 4.059 12.738 11.493 12.738 7.433 0 11.487-4.881 11.487-12.738C46.85 4.787 42.901.026 35.363.026zm0 21.462c-5.05 0-5.749-4.193-5.749-8.719 0-4.52.699-8.714 5.749-8.714 5.044 0 5.738 4.192 5.738 8.714 0 4.525-.694 8.719-5.738 8.719z"></path></svg></div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden sm:block"><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/blog">Blog</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/about">About</a></div><button aria-label="Toggle Dark Mode" type="button" class="w-8 h-8 p-1 ml-1 mr-1 rounded sm:ml-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button><div class="sm:hidden"><button type="button" class="w-8 h-8 py-1 ml-1 mr-1 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed w-full h-full top-24 right-0 bg-gray-200 dark:bg-gray-800 opacity-95 z-10 transform ease-in-out duration-300 translate-x-full"><button type="button" aria-label="toggle modal" class="fixed w-full h-full cursor-auto focus:outline-none"></button><nav class="fixed h-full mt-8"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/blog">Blog</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/about">About</a></div></nav></div></div></div></header><main class="mb-auto"><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-5xl xl:px-0"><article><div class="xl:divide-y xl:divide-gray-200 xl:dark:divide-gray-700"><header class="pt-6 xl:pb-6"><div class="space-y-1 text-center"><dl class="space-y-10"><div><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2022-03-10T00:00:00.000Z">Thursday, March 10, 2022</time></dd></div></dl><div><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">Spark on Kubernetes tại Fossil</h1></div></div></header><div class="pb-8 divide-y divide-gray-200 xl:divide-y-0 dark:divide-gray-700 xl:grid xl:grid-cols-4 xl:gap-x-6" style="grid-template-rows:auto 1fr"><dl class="pt-6 pb-10 xl:pt-11 xl:border-b xl:border-gray-200 xl:dark:border-gray-700"><dt class="sr-only">Authors</dt><dd><ul class="flex justify-center space-x-8 xl:block sm:space-x-12 xl:space-x-0 xl:space-y-8"><li class="flex items-center space-x-2"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2738%27%20height=%2738%27/%3e"/></span><img alt="avatar" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="w-10 h-10 rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="avatar" srcSet="https://avatars.githubusercontent.com/u/5009534?v=4?imwidth=48 1x, https://avatars.githubusercontent.com/u/5009534?v=4?imwidth=96 2x" src="https://avatars.githubusercontent.com/u/5009534?v=4?imwidth=96" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="w-10 h-10 rounded-full" loading="lazy"/></noscript></span><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-gray-100"><a href="/author/duyet">Duyet Le</a></dd><dt class="sr-only">Twitter</dt><dd><a target="_blank" rel="noopener noreferrer" href="https://github.com/duyet" class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400">@duyet</a></dd></dl></li></ul></dd></dl><div class="divide-y divide-gray-200 dark:divide-gray-700 xl:pb-0 xl:col-span-3 xl:row-span-2"><div class="pt-10 pb-8 prose dark:prose-dark max-w-none"><p>Tại <a target="_blank" rel="noopener noreferrer" href="https://sites.google.com/fossil.com/fossil-vietnam/home">Fossil</a>,
có hàng trăm triệu log records được thu thập mỗi ngày,
được xử lý và lưu trữ trong các Data Warehouse bởi hệ thống <strong>Fossil Data Platform</strong>.
Data Platform là một hệ thống event-driven được thiết kế dựa trên Lambda Architecture
gồm một near-realtime layer và một batch layer. Near-realtime layer cho phép data từ
lúc đẩy vào hệ thống cho đến khi xuất hiện ở đầu cuối có độ trễ tối đa 15 phút.
Batch layer sẽ tính toán bộ data lại một lần nữa, vào cuối mỗi ngày, để đảm bảo data
được chính xác và tối ưu hóa để lưu trữ lâu dài.</p>
<p>Hệ thống được triển khai trên Kubernetes Cluster bao gồm nhiều thành phần.
Một số thành phần có thể kể đến như: <em>API Ingession</em>, <a target="_blank" rel="noopener noreferrer" href="https://debezium.io"><em>CDC</em></a>,
<a target="_blank" rel="noopener noreferrer" href="https://docs.confluent.io/platform/current/connect/index.html"><em>Kafka Connector</em></a>,
các <em>Parser</em> và <em>Transformer</em> xử lý raw data.
<a target="_blank" rel="noopener noreferrer" href="https://airflow.apache.org/"><strong>Apache Airflow</strong></a> và <a target="_blank" rel="noopener noreferrer" href="https://spark.apache.org/"><strong>Apache Spark</strong></a>
cũng được triển khai trên <a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io"><strong>Kubernetes</strong></a>, quản lý bởi các
<a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">Kubernetes Operators</a>.</p>
<p>Apache Spark được chọn làm công nghệ cho Batch layer bởi khả năng xử lý
một lượng lớn data cùng một lúc. Ở thiết kế ban đầu, team data chọn sử dụng
Apache Spark trên <strong>AWS EMR</strong> do có sẵn và triển khai nhanh chóng.
Dần dần, AWS EMR bộc lộ một số điểm hạn chế trên môi trường Production.</p>
<p>Trong bài viết này, mình sẽ nói về tại sao và làm thế nào team
Data chuyển từ Spark trên AWS EMR sang Kubernetes.</p>
<div class="toc"><p>Trong bài này:</p><ul><li><a href="#1-apache-spark-trên-aws-emr">1. Apache Spark trên AWS EMR</a></li>
<li><a href="#2-spark-on-kubernetes---livy">2. Spark on Kubernetes - Livy</a></li><li><a href="#3-spark-on-kubernetes---spark-operator">3. Spark on Kubernetes - Spark Operator</a><ul><li><a href="#31-spark-operator">3.1. Spark Operator</a></li>
<li><a href="#32-spark-submit-worker">3.2. Spark Submit Worker</a></li>
<li><a href="#33-spark-jobs-ui">3.3. Spark Jobs UI</a></li>
<li><a href="#34-spark-history-server">3.4. Spark History Server</a></li></ul></li><li><a href="#4-performance-tuning-on-kubernetes">4. Performance Tuning on Kubernetes</a></li>
<li><a href="#5-kết">5. Kết</a></li>
<li><a href="#6-references">6. References</a></li></ul></div>
<h1>1. Apache Spark trên AWS EMR</h1>
<p>Trong thế giới của Data Engineering thì <a target="_blank" rel="noopener noreferrer" href="https://spark.apache.org/"><strong>Apache Spark</strong></a> không còn quá xa lạ.
Spark là open source với mục đích triển khai một hệ thống tính toán in-memory và massively parallel.
Spark được sử dụng rộng rãi trong nhiều lĩnh vực xử lý Big Data, từ Data Analytics đến Machine Learning.
Spark được thiết kế để có thể chạy ở Standalone Mode cũng như trên Mesos, YARN và Kubernetes.</p>
<p>Ở thiết kế đầu tiên, team Fossil Data Platform thiết kế sử dụng Apache Spark
để chạy các Jobs cùng với Apache Hive trên AWS EMR. Điều này hết sức đơn giản
do việc thiết lập cụm AWS EMR khá dễ dàng và nhanh chóng.
Dần dần sau một khoảng thời gian, team nhận ra có một số điểm yếu:</p>
<ul>
<li>Tại thời điểm đó AWS chưa ra mắt <em>EMR Serverless</em> và <em>EMR on EKS</em>, việc scale thêm EC2 Node tốn thời gian do phải bootstrap (cài đặt và khởi động) 1 loạt các services cần thiết.</li>
<li>Trên mỗi Node sẽ tốn 1 phần resources overhead để chạy các services đó (Spark, Livy, Zeppelin, Hive, HDFS, Monitoring, …).</li>
<li>Chi phí quản lý EMR Cluster.</li>
<li>HA trên EMR bắt buộc bạn phải có 3 node master chạy song song, nếu 1 node master chết thì node khác lên thay, nhưng bình thường sẽ lãng phí 2 node backup không làm gì cả.</li>
<li>...</li>
</ul>
<p>Trong khi toàn bộ hệ thống Data Platform được thiết kế dưới dạng micro-services
và <em>event-driven architecture</em> với nhiều thành phần chạy trên Kubernetes,
team bắt đầu nghĩ đến việc deploy Spark Jobs trên Kubernetes thay vì EMR, có một số ưu điểm có thể kể đến:</p>
<ul>
<li>Tiết kiệm chi phí, bao gồm chi phí cho việc đợi provisioning và bootstrapping phức tạp, costing được tính theo giây, việc này cũng giúp loại bỏ chi phí quản lý EMR cluster, khoảng <strong>$700-$800</strong> cho một tháng (chưa bao gồm chi phí EC2).</li>
<li>Spark trên YARN cũng tốn chi phí maintenance không nhỏ.</li>
<li>Tiết kiệm chi phí do không phải duy trì một lúc 3 Node Master HA.</li>
<li>Không thể chạy nhiều version của Spark khác nhau, ví dụ đang sử dụng Spark 2.4.x, bạn cần upgrade một số Application lên Spark 3.x để dùng tính năng mới, bắt buộc phải upgrade các Application cũ hoặc cài đặt một Cluster EMR mới. Ngược lại Spark trên Kubernetes cho phép chạy các driver, executer trên các Kubernetes Pod, mỗi Pod gồm 1 container nên có thể isolated workloads dễ dàng. Ngoài ra có thể thừa hưởng được mọi tính năng của Kubernetes như:<!-- -->
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/">Request/Limit</a>: điều chỉnh hay giới hạn resources (mem, cpu), số lượng Pod cho mỗi Spark Application.</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/">Namespace</a>: Kubernetes Namespace còn cho phép phân quyền cho các team, các môi trường với lượng resources xác định nữa (e.g. namespace: <code>data-prod</code>, <code>data-stag</code>, <code>data-dev</code>, …)</li>
<li>Tận dụng được <a target="_blank" rel="noopener noreferrer" href="https://github.com/kubernetes/autoscaler">Kubernetes Autoscaler</a> và có khả năng scale-to-zero.</li>
<li><a target="_blank" rel="noopener noreferrer" href="https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/">Node Selector và Affinity</a>: cho phép chọn loại Node tùy theo tính chất của Jobs đó, ví dụ một số Jobs cần nhiều Mem, trong khi một khố Jobs khác cần nhiều CPU.</li>
</ul>
</li>
</ul>
<h1>2. Spark on Kubernetes - Livy</h1>
<p>Kể từ 2.3.x là Spark đã hỗ trợ chạy trên cluster quản lý bởi Kubernetes. Chúng ta có thể submit một Spark Application bất kỳ trực tiếp bằng cách sử dụng <code>spark-submit</code> trên comand line, chỉ cần thay <code>--master</code> đến địa chỉ của Kubernetes <code>k8s://&lt;api_server_host&gt;:&lt;k8s-apiserver-port&gt;</code></p>
<p>Ví dụ để chạy Spark Pi trên Cluster mode, hãy xem ví dụ sau:</p>
<div class="relative"><pre><code class="language-bash">$ bin/spark-submit \
   --master k8s://https://&lt;k8s-apiserver-host&gt;:&lt;k8s-apiserver-port&gt; \
   --deploy-mode cluster \
   --name spark-pi \
   --class org.apache.spark.examples.SparkPi \
   --conf spark.executor.instances=5 \
   --conf spark.kubernetes.container.image=&lt;spark-image&gt; \
   local:///path/to/examples.jar
</code></pre></div>
<p>Chú ý là <code>k8s://https://</code> mình không viết nhầm đâu nhé.</p>
<p>Nhu cầu để có thể submit một loạt jobs hàng ngày, team sử dụng <strong><a target="_blank" rel="noopener noreferrer" href="https://livy.incubator.apache.org/">Apache Livy</a></strong> trên Kubernetes, với kiến trúc như dưới đây:</p>
<p><img src="/media/2022/03/spark-k8s-1.png" alt=""/></p>
<p>Team sử dụng Livy, đây là một service cho phép tương tác với Spark Cluster thông qua RESTful API. Livy đã từng được sử dụng trên EMR, ở Kubernetes chỉ cần deploy Livy thông qua Helm một cách dễ dàng. Xem thêm cách cài đặt Livy ở đây. Để trigger Livy có nhiều cách, team sử dụng Airflow như là một scheduler, có nhiều loại DAGs tùy vào tính chất của mỗi Jobs, các DAG sẽ trigger Livy, theo dõi trạng thái của Jobs đó cũng thông qua API, retry hoặc alert khi cần thiết. DAG cũng có nhiệm vụ kiểm tra dữ liệu (data validation) kết quả đầu ra (output) cho mỗi jobs.</p>
<p>Tuy nhiên lại có một số điểm hạn chế như do delay từ Airflow Scheduler, Livy cũng dễ bị stuck. Nếu một jobs chạy lâu nhưng Livy bị restart thì Jobs đó cũng bị ảnh hưởng theo. Team quyết định nâng cấp.</p>
<h1>3. Spark on Kubernetes - Spark Operator</h1>
<p>Sau khi đánh giá khả năng của Spark Operator bởi GCP Google, team quyết định đi đến phiên bản 2.0 của architecture. Các thành phần sẽ như hình dưới đây:</p>
<p><img src="/media/2022/03/spark-k8s-2-operator.png" alt=""/></p>
<p>Ở kiến trúc trên, vai trò của Data Engineer sẽ là:</p>
<ul>
<li>(1) generate ra <strong>Spark Jobs Artifacts</strong> và commit/push vào một Repo trên Git. Spark Jobs Artifacts sẽ có dạng như ví dụ này, có thể hiểu đây là một specs để Spark Operator có thể submit và quản lý Jobs trên namespace của mình. Có 2 loại CRDs của Spark Operator sinh ra để quản lý là <code>SparkApplication</code> và <code>ScheduledSparkApplication</code>.</li>
<li>(2) <strong>Spark Submit Worker</strong> là một Pod chạy trên Kubernetes, có nhiệm vụ đọc/sync những gì trên Git và apply vào Kubernetes thông qua Kubernetes API (hoạt động giống như <code>kubectl apply -f</code>).</li>
<li>(3) <strong>Spark Operator</strong> như mọi Operator khác, sẽ lắng nghe/đọc CRDs được submit vào cluster, sẽ specify, running, và cập nhật status của các Spark application. Từ một <code>SparkApplication</code> Spark Operator sẽ dựng một POD driver, POD driver sẽ request thêm từ Kubernetes để dựng thêm các POD executor, đến khi nào Spark Jobs thực hiện xong sẽ tự động terminate các pod này. Logs sẽ được lưu giữ ở S3 bucket.</li>
<li>(4) <strong>Spark History Server</strong> sẽ render logs từ S3 bucket, giúp team engineer dễ dàng hơn trong việc traceback lại các jobs cũ đã finish.</li>
<li>(5) <strong>Spark Jobs UI</strong> là một Web UI để quản lý tất cả các Spark Jobs trên Git, kiểm tra trạng thái của mỗi Jobs trên Cluster, monitor, data validation cũng như backfill.</li>
</ul>
<p>Hãy tìm hiểu xem một số thành phần chính đóng vai trò gì nhé.</p>
<h2>3.1. Spark Operator</h2>
<p>Spark Operator là một Kubernetes Operator được thiết kế cho Spark nhằm mục đích xác định và thực thi các Spark applications dễ dàng như các workloads khác trên Kubernetes, bằng cách sử dụng và quản lý một Kubernetes custom resources (CRD) để specifying, running, và update status của Spark applications.</p>
<p>Để tìm hiểu thêm bạn có thể xem qua về <a target="_blank" rel="noopener noreferrer" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/design.md">Design</a>, <a target="_blank" rel="noopener noreferrer" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md">API Specification</a>, và <a target="_blank" rel="noopener noreferrer" href="https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md">User Guide</a> trên Github.</p>
<p>Ví dụ để cài đặt Spark Operator trên namespace <code>spark-jobs</code> thông qua Helm chart, ở đây mình bật tính năng <code>webhook</code>. Tùy vào hệ thống quản lý của bạn mà có thể cài đặt thông quan FluxCD hay ArgoCD, ở đây mình sử dụng <code>helm</code> cli đơn giản cho việc minh họa:</p>
<div class="relative"><pre><code class="language-bash">helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator
helm install spark-operator \
   spark-operator/spark-operator \
   --namespace spark-jobs \
   --set sparkJobNamespace=spark-jobs \
   --set webhook.enable=true
</code></pre></div>
<h2>3.2. Spark Submit Worker</h2>
<p>Một <code>SparkApplication</code> có về cơ bản là một resource CRD, có thể được apply vào cluster bằng <code>kubectl</code>, như ví dụ dưới đây:</p>
<div class="relative"><pre><code class="language-yaml"># spark-pi.yaml
---
apiVersion: &#x27;sparkoperator.k8s.io/v1beta2&#x27;
kind: SparkApplication
metadata:
  name: pyspark-pi
  namespace: spark-jobs
spec:
  type: Python
  pythonVersion: &#x27;3&#x27;
  mode: cluster
  image: &#x27;gcr.io/spark-operator/spark-py:v3.1.1&#x27;
  imagePullPolicy: Always
  mainApplicationFile: local:///opt/spark/examples/src/main/python/pi.py
  sparkVersion: &#x27;3.1.1&#x27;
  restartPolicy:
    type: OnFailure
    onFailureRetries: 3
    onFailureRetryInterval: 10
    onSubmissionFailureRetries: 5
    onSubmissionFailureRetryInterval: 20
  driver:
    cores: 1
    coreLimit: &#x27;1200m&#x27;
    memory: &#x27;512m&#x27;
    labels:
      version: 3.1.1
    serviceAccount: spark
  executor:
    cores: 1
    instances: 1
    memory: &#x27;512m&#x27;
    labels:
      version: 3.1.1
</code></pre></div>
<p>Để submit SparkPi này vào Kubernetes, bạn chỉ cần sử dụng:</p>
<div class="relative"><pre><code class="language-bash">kubectl apply -f spark-pi.yaml
kubectl get sparkapp
</code></pre></div>
<p>Để tự động hóa, <strong>Spark Submit Worker</strong> là một Cronjob Pod để định kỳ (~5ph) sync với Git Repo và apply mọi spark app dưới dạng các file YAML và mọi thay đổi lên cluster. Có 2 dạng artifacts mà Spark Submit quản lý là <code>SparkApplication</code> và <code>ScheduledSparkApplication</code> như đã nói ở trên.</p>
<p>Việc quản lý các Spark Application dưới dạng YAML specs còn giúp có thêm một số lợi ích của <strong>GitOps</strong>: mọi thay đổi đều được Git Versioning, phân quyền trên Git, review thay đổi, approve hoặc reject thay đổi, dễ dàng rollback bằng cách revert git, …</p>
<h2>3.3. Spark Jobs UI</h2>
<p>Spark Jobs UI hay Spark Jobs Dashboard là một Web UI để quản lý Spark Jobs và artifacts được generated hoặc customized bởi engineers. Dashboard được viết bằng Typescript và Next.js, gồm một số tính năng cơ bản như:</p>
<ul>
<li>Liệt kê mọi Spark Jobs artifacts</li>
<li>Xem nội dung của từng Spark Application YAML files</li>
<li>Xem thông tin status của mỗi Scheduled Spark Application như là <code>scheduleStatus</code>, <code>lastRun</code>, <code>nextRun</code>, ...</li>
<li>Kiểm tra nhanh dữ liệu output (basic data validation) cho mỗi jobs theo interval của Jobs đó. Ví dụ một jobs theo ngày (daily), UI sẽ kiểm tra mỗi ngày xem có data của ngày hôm đó có hợp lệ không.</li>
<li>Thống kê cơ bản như số Jobs đang chạy, đang pending, số lượng Jobs lỗi, resources (CPU/Memory) sử dụng, …</li>
<li>Backfill: có thể trigger chạy lại cho một hoặc nhiều jobs, một ngày hoặc nhiều ngày.</li>
</ul>
<p>Hãy xem một số screenshot dưới đây để có cái hình cụ thể hơn:</p>
<p><img src="/media/2022/03/spark-k8s-3.png" alt="Fossil Spark UI"/></p>
<p><img src="/media/2022/03/spark-k8s-4.png" alt="Data Validation"/></p>
<p><img src="/media/2022/03/spark-k8s-5.png" alt="Backfill: trigger để chạy lại Jobs cho một hoặc một số ngày cụ thể trong quá khứ"/></p>
<p><img src="/media/2022/03/spark-k8s-6.png" alt="Có thể custom một số config lúc chạy backfill, như resources, số lượng executor, spark version, ..."/></p>
<h2>3.4. Spark History Server</h2>
<p>Spark History Server là một Spark Web UI có sẵn của Spark, dùng để monitor trạng thái và tài nguyên sử dụng cho Spark App. Spark History Server được dựng lên để đọc lại logs của các Jobs đã hoàn thành trước đó lưu trên S3 bucket. Mỗi <code>SparkApplication</code> sẽ được config để push Spark events lên S3:</p>
<div class="relative"><pre><code class="language-yaml">spec:
  sparkConf:
    &#x27;spark.eventLog.enabled&#x27;: &#x27;true&#x27;
    &#x27;spark.eventLog.dir&#x27;: &#x27;s3a://fossil-spark/logs/&#x27;
</code></pre></div>
<p>Spark History Server cũng có thể được cài đặt thông qua <a target="_blank" rel="noopener noreferrer" href="https://artifacthub.io/packages/helm/spot/spark-history-server">this Helm Chart</a>, chỉ cần trỏ đúng đường dẫn của <code>logDirectory</code> vào đúng vị trí S3 bucket mà Spark đã gửi lên.</p>
<div class="relative"><pre><code class="language-yaml">helm repo add stable https://kubernetes-charts.storage.googleapis.com
helm install stable/spark-history-server \
--namespace spark-jobs \
--set enableS3=true \
--set logDirectory=s3a://fossil-spark/logs/
</code></pre></div>
<p><img src="/media/2022/03/spark-k8s-7.png" alt="Untitled"/></p>
<h1>4. Performance Tuning on Kubernetes</h1>
<p>Có rất nhiều tối ưu được được thực hiện do tính chất Spark trên Kubernetes + AWS sẽ có chút khác biệt với Spark trên YARN.
Một số có thể kể đến mà bạn có thể xem thêm ở đây
<a href="/2021/04/spark-kubernetes-performance-tuning.html">Spark on Kubernetes Performance Tuning</a> hoặc dễ dàng tìm kiếm trên Google:</p>
<ul>
<li>Using Volcano Scheduler for Gang schedule</li>
<li>Using Kryo serialization</li>
<li>Ignoring Data Locality because of S3 data source.</li>
<li>I/O for S3</li>
<li>Tuning Java</li>
<li>Enabled Dynamic Allocation and Dynamic Allocation Shuffle File Tracking</li>
<li>Using Kubernetes Node Spot instance for the executors.</li>
</ul>
<h1>5. Kết</h1>
<p>Như vậy là mọi người đã có thể hình dung được cách mà team Data Platform tại Fossil sử dụng vận hành Apache Spark trên Kubernetes.</p>
<p>Do có nhiều chi tiết, nhiều vấn đề kỹ thuật, cách cài đặt, cách tối ưu, … mà mình khó có thể đề cập hết được, do đó bài viết chỉ dừng lại ở tính chất giới thiệu tổng quát. Mình sẽ cố gắng chi tiết hóa các vấn đề ở các bài viết khác nếu có thể trong tương lai.</p>
<div class="bg-emerald-600 p-5"><p>Bài viết cũng được đăng tại
<a href="https://blog.duyet.net/2022/03/spark-kubernetes-at-fossil">duyet.net</a>.</p></div>
<div class="bg-blue-100 border-t border-b border-blue-500"><p>Hiện tại Fossil Cloud Data đang open cho các vị trí (Sr) Data Engineer,
<a href="https://sites.google.com/fossil.com/fossil-vietnam/careers/jobs" target="_blank">xem thêm JD tại đây</a>
hoặc gửi CV của bạn về email <strong>lvduyet (at) fossil.com</strong> để cùng trao đổi thêm nhé.</p></div>
<h1>6. References</h1>
<ul>
<li>https://kubernetes.io</li>
<li>https://spark.apache.org</li>
<li>https://airflow.apache.org</li>
<li>https://livy.incubator.apache.org</li>
<li>https://github.com/GoogleCloudPlatform/spark-on-k8s-operator</li>
<li>https://kubernetes.io/docs/concepts/extend-kubernetes/operator</li>
</ul></div><div class="pt-6 pb-6 text-sm text-gray-700 dark:text-gray-300"><a target="_blank" rel="nofollow" href="https://mobile.twitter.com/search?q=https%3A%2F%2Ffossil-engineering.github.io%2Fblog%2Fspark-on-kubernetes-at-fossil">Discuss on Twitter</a> • <a target="_blank" rel="noopener noreferrer" href="https://github.com/fossil-engineering/fossil-engineering.github.io/blob/master/data/blog/2022-03-10-spark-on-kubernetes-at-fossil.md">View on GitHub</a></div></div><footer><div class="text-sm font-medium leading-5 divide-gray-200 xl:divide-y dark:divide-gray-700 xl:col-start-1 xl:row-start-2"><div class="py-4 xl:py-8"><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Tags</h2><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/engineering">engineering</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/data">data</a></div></div><div class="flex justify-between py-4 xl:block xl:space-y-8 xl:py-8"><div><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Previous Article</h2><div class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a href="/blog/1234">1,234 days — Day 1 at Fossil</a></div></div><div><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Next Article</h2><div class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a href="/blog/working-from-home">Working From Home</a></div></div></div></div><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/blog">← Back to the blog</a></div></footer></div></div></article></div></main><footer><div class="flex flex-col items-center mt-16"><div class="flex mb-3 space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:people@fossil.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/fossil-engineering"><span class="sr-only">github</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/company/fossilvietnamcareers/"><span class="sr-only">linkedin</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></div><div class="flex mb-2 space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>© 2022</div><div> • </div><a href="/">Fossil Engineering</a></div><div class="mb-8 text-sm text-gray-500 dark:text-gray-400"><a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog">Tailwind Nextjs Theme</a></div></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"mdxSource":"var Component=(()=\u003e{var p=Object.create;var c=Object.defineProperty;var d=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var m=Object.getPrototypeOf,u=Object.prototype.hasOwnProperty;var k=(r,e)=\u003e()=\u003e(e||r((e={exports:{}}).exports,e),e.exports),b=(r,e)=\u003e{for(var t in e)c(r,t,{get:e[t],enumerable:!0})},a=(r,e,t,h)=\u003e{if(e\u0026\u0026typeof e==\"object\"||typeof e==\"function\")for(let i of g(e))!u.call(r,i)\u0026\u0026i!==t\u0026\u0026c(r,i,{get:()=\u003ee[i],enumerable:!(h=d(e,i))||h.enumerable});return r};var v=(r,e,t)=\u003e(t=r!=null?p(m(r)):{},a(e||!r||!r.__esModule?c(t,\"default\",{value:r,enumerable:!0}):t,r)),y=r=\u003ea(c({},\"__esModule\",{value:!0}),r);var l=k((K,s)=\u003e{s.exports=_jsx_runtime});var x={};b(x,{default:()=\u003eA,frontmatter:()=\u003eS});var n=v(l()),S={title:\"Spark on Kubernetes t\\u1EA1i Fossil\",authors:[\"duyet\"],date:\"2022-03-10\",tags:[\"engineering\",\"data\"],summary:\"Apache Spark \\u0111\\u01B0\\u1EE3c ch\\u1ECDn l\\xE0m c\\xF4ng ngh\\u1EC7 cho Batch layer b\\u1EDFi kh\\u1EA3 n\\u0103ng x\\u1EED l\\xFD m\\u1ED9t l\\u01B0\\u1EE3ng l\\u1EDBn data c\\xF9ng m\\u1ED9t l\\xFAc. \\u1EDE thi\\u1EBFt k\\u1EBF ban \\u0111\\u1EA7u, team data ch\\u1ECDn s\\u1EED d\\u1EE5ng Apache Spark tr\\xEAn AWS EMR do c\\xF3 s\\u1EB5n v\\xE0 tri\\u1EC3n khai nhanh ch\\xF3ng. D\\u1EA7n d\\u1EA7n, AWS EMR b\\u1ED9c l\\u1ED9 m\\u1ED9t s\\u1ED1 \\u0111i\\u1EC3m h\\u1EA1n ch\\u1EBF tr\\xEAn m\\xF4i tr\\u01B0\\u1EDDng Production. Trong b\\xE0i vi\\u1EBFt n\\xE0y, m\\xECnh s\\u1EBD n\\xF3i v\\u1EC1 t\\u1EA1i sao v\\xE0 l\\xE0m th\\u1EBF n\\xE0o team Data chuy\\u1EC3n t\\u1EEB Spark tr\\xEAn AWS EMR sang Kubernetes.\",layout:\"PostLayout\"};function o(r){let e=Object.assign({p:\"p\",a:\"a\",strong:\"strong\",em:\"em\",h1:\"h1\",ul:\"ul\",li:\"li\",code:\"code\",pre:\"pre\",img:\"img\",h2:\"h2\"},r.components);return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsxs)(e.p,{children:[\"T\\u1EA1i \",(0,n.jsx)(e.a,{href:\"https://sites.google.com/fossil.com/fossil-vietnam/home\",children:\"Fossil\"}),`,\nc\\xF3 h\\xE0ng tr\\u0103m tri\\u1EC7u log records \\u0111\\u01B0\\u1EE3c thu th\\u1EADp m\\u1ED7i ng\\xE0y,\n\\u0111\\u01B0\\u1EE3c x\\u1EED l\\xFD v\\xE0 l\\u01B0u tr\\u1EEF trong c\\xE1c Data Warehouse b\\u1EDFi h\\u1EC7 th\\u1ED1ng `,(0,n.jsx)(e.strong,{children:\"Fossil Data Platform\"}),`.\nData Platform l\\xE0 m\\u1ED9t h\\u1EC7 th\\u1ED1ng event-driven \\u0111\\u01B0\\u1EE3c thi\\u1EBFt k\\u1EBF d\\u1EF1a tr\\xEAn Lambda Architecture\ng\\u1ED3m m\\u1ED9t near-realtime layer v\\xE0 m\\u1ED9t batch layer. Near-realtime layer cho ph\\xE9p data t\\u1EEB\nl\\xFAc \\u0111\\u1EA9y v\\xE0o h\\u1EC7 th\\u1ED1ng cho \\u0111\\u1EBFn khi xu\\u1EA5t hi\\u1EC7n \\u1EDF \\u0111\\u1EA7u cu\\u1ED1i c\\xF3 \\u0111\\u1ED9 tr\\u1EC5 t\\u1ED1i \\u0111a 15 ph\\xFAt.\nBatch layer s\\u1EBD t\\xEDnh to\\xE1n b\\u1ED9 data l\\u1EA1i m\\u1ED9t l\\u1EA7n n\\u1EEFa, v\\xE0o cu\\u1ED1i m\\u1ED7i ng\\xE0y, \\u0111\\u1EC3 \\u0111\\u1EA3m b\\u1EA3o data\n\\u0111\\u01B0\\u1EE3c ch\\xEDnh x\\xE1c v\\xE0 t\\u1ED1i \\u01B0u h\\xF3a \\u0111\\u1EC3 l\\u01B0u tr\\u1EEF l\\xE2u d\\xE0i.`]}),`\n`,(0,n.jsxs)(e.p,{children:[`H\\u1EC7 th\\u1ED1ng \\u0111\\u01B0\\u1EE3c tri\\u1EC3n khai tr\\xEAn Kubernetes Cluster bao g\\u1ED3m nhi\\u1EC1u th\\xE0nh ph\\u1EA7n.\nM\\u1ED9t s\\u1ED1 th\\xE0nh ph\\u1EA7n c\\xF3 th\\u1EC3 k\\u1EC3 \\u0111\\u1EBFn nh\\u01B0: `,(0,n.jsx)(e.em,{children:\"API Ingession\"}),\", \",(0,n.jsx)(e.a,{href:\"https://debezium.io\",children:(0,n.jsx)(e.em,{children:\"CDC\"})}),`,\n`,(0,n.jsx)(e.a,{href:\"https://docs.confluent.io/platform/current/connect/index.html\",children:(0,n.jsx)(e.em,{children:\"Kafka Connector\"})}),`,\nc\\xE1c `,(0,n.jsx)(e.em,{children:\"Parser\"}),\" v\\xE0 \",(0,n.jsx)(e.em,{children:\"Transformer\"}),` x\\u1EED l\\xFD raw data.\n`,(0,n.jsx)(e.a,{href:\"https://airflow.apache.org/\",children:(0,n.jsx)(e.strong,{children:\"Apache Airflow\"})}),\" v\\xE0 \",(0,n.jsx)(e.a,{href:\"https://spark.apache.org/\",children:(0,n.jsx)(e.strong,{children:\"Apache Spark\"})}),`\nc\\u0169ng \\u0111\\u01B0\\u1EE3c tri\\u1EC3n khai tr\\xEAn `,(0,n.jsx)(e.a,{href:\"https://kubernetes.io\",children:(0,n.jsx)(e.strong,{children:\"Kubernetes\"})}),`, qu\\u1EA3n l\\xFD b\\u1EDFi c\\xE1c\n`,(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator/\",children:\"Kubernetes Operators\"}),\".\"]}),`\n`,(0,n.jsxs)(e.p,{children:[`Apache Spark \\u0111\\u01B0\\u1EE3c ch\\u1ECDn l\\xE0m c\\xF4ng ngh\\u1EC7 cho Batch layer b\\u1EDFi kh\\u1EA3 n\\u0103ng x\\u1EED l\\xFD\nm\\u1ED9t l\\u01B0\\u1EE3ng l\\u1EDBn data c\\xF9ng m\\u1ED9t l\\xFAc. \\u1EDE thi\\u1EBFt k\\u1EBF ban \\u0111\\u1EA7u, team data ch\\u1ECDn s\\u1EED d\\u1EE5ng\nApache Spark tr\\xEAn `,(0,n.jsx)(e.strong,{children:\"AWS EMR\"}),` do c\\xF3 s\\u1EB5n v\\xE0 tri\\u1EC3n khai nhanh ch\\xF3ng.\nD\\u1EA7n d\\u1EA7n, AWS EMR b\\u1ED9c l\\u1ED9 m\\u1ED9t s\\u1ED1 \\u0111i\\u1EC3m h\\u1EA1n ch\\u1EBF tr\\xEAn m\\xF4i tr\\u01B0\\u1EDDng Production.`]}),`\n`,(0,n.jsx)(e.p,{children:`Trong b\\xE0i vi\\u1EBFt n\\xE0y, m\\xECnh s\\u1EBD n\\xF3i v\\u1EC1 t\\u1EA1i sao v\\xE0 l\\xE0m th\\u1EBF n\\xE0o team\nData chuy\\u1EC3n t\\u1EEB Spark tr\\xEAn AWS EMR sang Kubernetes.`}),`\n`,(0,n.jsxs)(\"div\",{className:\"toc\",children:[(0,n.jsx)(\"p\",{children:\"Trong b\\xE0i n\\xE0y:\"}),(0,n.jsxs)(\"ul\",{children:[(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#1-apache-spark-tr\\xEAn-aws-emr\",children:\"1. Apache Spark tr\\xEAn AWS EMR\"})}),`\n`,(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#2-spark-on-kubernetes---livy\",children:\"2. Spark on Kubernetes - Livy\"})}),(0,n.jsxs)(\"li\",{children:[(0,n.jsx)(\"a\",{href:\"#3-spark-on-kubernetes---spark-operator\",children:\"3. Spark on Kubernetes - Spark Operator\"}),(0,n.jsxs)(\"ul\",{children:[(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#31-spark-operator\",children:\"3.1. Spark Operator\"})}),`\n`,(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#32-spark-submit-worker\",children:\"3.2. Spark Submit Worker\"})}),`\n`,(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#33-spark-jobs-ui\",children:\"3.3. Spark Jobs UI\"})}),`\n`,(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#34-spark-history-server\",children:\"3.4. Spark History Server\"})})]})]}),(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#4-performance-tuning-on-kubernetes\",children:\"4. Performance Tuning on Kubernetes\"})}),`\n`,(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#5-k\\u1EBFt\",children:\"5. K\\u1EBFt\"})}),`\n`,(0,n.jsx)(\"li\",{children:(0,n.jsx)(\"a\",{href:\"#6-references\",children:\"6. References\"})})]})]}),`\n`,(0,n.jsx)(e.h1,{children:\"1. Apache Spark tr\\xEAn AWS EMR\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Trong th\\u1EBF gi\\u1EDBi c\\u1EE7a Data Engineering th\\xEC \",(0,n.jsx)(e.a,{href:\"https://spark.apache.org/\",children:(0,n.jsx)(e.strong,{children:\"Apache Spark\"})}),` kh\\xF4ng c\\xF2n qu\\xE1 xa l\\u1EA1.\nSpark l\\xE0 open source v\\u1EDBi m\\u1EE5c \\u0111\\xEDch tri\\u1EC3n khai m\\u1ED9t h\\u1EC7 th\\u1ED1ng t\\xEDnh to\\xE1n in-memory v\\xE0 massively parallel.\nSpark \\u0111\\u01B0\\u1EE3c s\\u1EED d\\u1EE5ng r\\u1ED9ng r\\xE3i trong nhi\\u1EC1u l\\u0129nh v\\u1EF1c x\\u1EED l\\xFD Big Data, t\\u1EEB Data Analytics \\u0111\\u1EBFn Machine Learning.\nSpark \\u0111\\u01B0\\u1EE3c thi\\u1EBFt k\\u1EBF \\u0111\\u1EC3 c\\xF3 th\\u1EC3 ch\\u1EA1y \\u1EDF Standalone Mode c\\u0169ng nh\\u01B0 tr\\xEAn Mesos, YARN v\\xE0 Kubernetes.`]}),`\n`,(0,n.jsx)(e.p,{children:`\\u1EDE thi\\u1EBFt k\\u1EBF \\u0111\\u1EA7u ti\\xEAn, team Fossil Data Platform thi\\u1EBFt k\\u1EBF s\\u1EED d\\u1EE5ng Apache Spark\n\\u0111\\u1EC3 ch\\u1EA1y c\\xE1c Jobs c\\xF9ng v\\u1EDBi Apache Hive tr\\xEAn AWS EMR. \\u0110i\\u1EC1u n\\xE0y h\\u1EBFt s\\u1EE9c \\u0111\\u01A1n gi\\u1EA3n\ndo vi\\u1EC7c thi\\u1EBFt l\\u1EADp c\\u1EE5m AWS EMR kh\\xE1 d\\u1EC5 d\\xE0ng v\\xE0 nhanh ch\\xF3ng.\nD\\u1EA7n d\\u1EA7n sau m\\u1ED9t kho\\u1EA3ng th\\u1EDDi gian, team nh\\u1EADn ra c\\xF3 m\\u1ED9t s\\u1ED1 \\u0111i\\u1EC3m y\\u1EBFu:`}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"T\\u1EA1i th\\u1EDDi \\u0111i\\u1EC3m \\u0111\\xF3 AWS ch\\u01B0a ra m\\u1EAFt \",(0,n.jsx)(e.em,{children:\"EMR Serverless\"}),\" v\\xE0 \",(0,n.jsx)(e.em,{children:\"EMR on EKS\"}),\", vi\\u1EC7c scale th\\xEAm EC2 Node t\\u1ED1n th\\u1EDDi gian do ph\\u1EA3i bootstrap (c\\xE0i \\u0111\\u1EB7t v\\xE0 kh\\u1EDFi \\u0111\\u1ED9ng) 1 lo\\u1EA1t c\\xE1c services c\\u1EA7n thi\\u1EBFt.\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Tr\\xEAn m\\u1ED7i Node s\\u1EBD t\\u1ED1n 1 ph\\u1EA7n resources overhead \\u0111\\u1EC3 ch\\u1EA1y c\\xE1c services \\u0111\\xF3 (Spark, Livy, Zeppelin, Hive, HDFS, Monitoring, \\u2026).\"}),`\n`,(0,n.jsx)(e.li,{children:\"Chi ph\\xED qu\\u1EA3n l\\xFD EMR Cluster.\"}),`\n`,(0,n.jsx)(e.li,{children:\"HA tr\\xEAn EMR b\\u1EAFt bu\\u1ED9c b\\u1EA1n ph\\u1EA3i c\\xF3 3 node master ch\\u1EA1y song song, n\\u1EBFu 1 node master ch\\u1EBFt th\\xEC node kh\\xE1c l\\xEAn thay, nh\\u01B0ng b\\xECnh th\\u01B0\\u1EDDng s\\u1EBD l\\xE3ng ph\\xED 2 node backup kh\\xF4ng l\\xE0m g\\xEC c\\u1EA3.\"}),`\n`,(0,n.jsx)(e.li,{children:\"...\"}),`\n`]}),`\n`,(0,n.jsxs)(e.p,{children:[`Trong khi to\\xE0n b\\u1ED9 h\\u1EC7 th\\u1ED1ng Data Platform \\u0111\\u01B0\\u1EE3c thi\\u1EBFt k\\u1EBF d\\u01B0\\u1EDBi d\\u1EA1ng micro-services\nv\\xE0 `,(0,n.jsx)(e.em,{children:\"event-driven architecture\"}),` v\\u1EDBi nhi\\u1EC1u th\\xE0nh ph\\u1EA7n ch\\u1EA1y tr\\xEAn Kubernetes,\nteam b\\u1EAFt \\u0111\\u1EA7u ngh\\u0129 \\u0111\\u1EBFn vi\\u1EC7c deploy Spark Jobs tr\\xEAn Kubernetes thay v\\xEC EMR, c\\xF3 m\\u1ED9t s\\u1ED1 \\u01B0u \\u0111i\\u1EC3m c\\xF3 th\\u1EC3 k\\u1EC3 \\u0111\\u1EBFn:`]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"Ti\\u1EBFt ki\\u1EC7m chi ph\\xED, bao g\\u1ED3m chi ph\\xED cho vi\\u1EC7c \\u0111\\u1EE3i provisioning v\\xE0 bootstrapping ph\\u1EE9c t\\u1EA1p, costing \\u0111\\u01B0\\u1EE3c t\\xEDnh theo gi\\xE2y, vi\\u1EC7c n\\xE0y c\\u0169ng gi\\xFAp lo\\u1EA1i b\\u1ECF chi ph\\xED qu\\u1EA3n l\\xFD EMR cluster, kho\\u1EA3ng \",(0,n.jsx)(e.strong,{children:\"$700-$800\"}),\" cho m\\u1ED9t th\\xE1ng (ch\\u01B0a bao g\\u1ED3m chi ph\\xED EC2).\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Spark tr\\xEAn YARN c\\u0169ng t\\u1ED1n chi ph\\xED maintenance kh\\xF4ng nh\\u1ECF.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Ti\\u1EBFt ki\\u1EC7m chi ph\\xED do kh\\xF4ng ph\\u1EA3i duy tr\\xEC m\\u1ED9t l\\xFAc 3 Node Master HA.\"}),`\n`,(0,n.jsxs)(e.li,{children:[\"Kh\\xF4ng th\\u1EC3 ch\\u1EA1y nhi\\u1EC1u version c\\u1EE7a Spark kh\\xE1c nhau, v\\xED d\\u1EE5 \\u0111ang s\\u1EED d\\u1EE5ng Spark 2.4.x, b\\u1EA1n c\\u1EA7n upgrade m\\u1ED9t s\\u1ED1 Application l\\xEAn Spark 3.x \\u0111\\u1EC3 d\\xF9ng t\\xEDnh n\\u0103ng m\\u1EDBi, b\\u1EAFt bu\\u1ED9c ph\\u1EA3i upgrade c\\xE1c Application c\\u0169 ho\\u1EB7c c\\xE0i \\u0111\\u1EB7t m\\u1ED9t Cluster EMR m\\u1EDBi. Ng\\u01B0\\u1EE3c l\\u1EA1i Spark tr\\xEAn Kubernetes cho ph\\xE9p ch\\u1EA1y c\\xE1c driver, executer tr\\xEAn c\\xE1c Kubernetes Pod, m\\u1ED7i Pod g\\u1ED3m 1 container n\\xEAn c\\xF3 th\\u1EC3 isolated workloads d\\u1EC5 d\\xE0ng. Ngo\\xE0i ra c\\xF3 th\\u1EC3 th\\u1EEBa h\\u01B0\\u1EDFng \\u0111\\u01B0\\u1EE3c m\\u1ECDi t\\xEDnh n\\u0103ng c\\u1EE7a Kubernetes nh\\u01B0:\",`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/\",children:\"Request/Limit\"}),\": \\u0111i\\u1EC1u ch\\u1EC9nh hay gi\\u1EDBi h\\u1EA1n resources (mem, cpu), s\\u1ED1 l\\u01B0\\u1EE3ng Pod cho m\\u1ED7i Spark Application.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/overview/working-with-objects/namespaces/\",children:\"Namespace\"}),\": Kubernetes Namespace c\\xF2n cho ph\\xE9p ph\\xE2n quy\\u1EC1n cho c\\xE1c team, c\\xE1c m\\xF4i tr\\u01B0\\u1EDDng v\\u1EDBi l\\u01B0\\u1EE3ng resources x\\xE1c \\u0111\\u1ECBnh n\\u1EEFa (e.g. namespace: \",(0,n.jsx)(e.code,{children:\"data-prod\"}),\", \",(0,n.jsx)(e.code,{children:\"data-stag\"}),\", \",(0,n.jsx)(e.code,{children:\"data-dev\"}),\", \\u2026)\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"T\\u1EADn d\\u1EE5ng \\u0111\\u01B0\\u1EE3c \",(0,n.jsx)(e.a,{href:\"https://github.com/kubernetes/autoscaler\",children:\"Kubernetes Autoscaler\"}),\" v\\xE0 c\\xF3 kh\\u1EA3 n\\u0103ng scale-to-zero.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.a,{href:\"https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/\",children:\"Node Selector v\\xE0 Affinity\"}),\": cho ph\\xE9p ch\\u1ECDn lo\\u1EA1i Node t\\xF9y theo t\\xEDnh ch\\u1EA5t c\\u1EE7a Jobs \\u0111\\xF3, v\\xED d\\u1EE5 m\\u1ED9t s\\u1ED1 Jobs c\\u1EA7n nhi\\u1EC1u Mem, trong khi m\\u1ED9t kh\\u1ED1 Jobs kh\\xE1c c\\u1EA7n nhi\\u1EC1u CPU.\"]}),`\n`]}),`\n`]}),`\n`]}),`\n`,(0,n.jsx)(e.h1,{children:\"2. Spark on Kubernetes - Livy\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"K\\u1EC3 t\\u1EEB 2.3.x l\\xE0 Spark \\u0111\\xE3 h\\u1ED7 tr\\u1EE3 ch\\u1EA1y tr\\xEAn cluster qu\\u1EA3n l\\xFD b\\u1EDFi Kubernetes. Ch\\xFAng ta c\\xF3 th\\u1EC3 submit m\\u1ED9t Spark Application b\\u1EA5t k\\u1EF3 tr\\u1EF1c ti\\u1EBFp b\\u1EB1ng c\\xE1ch s\\u1EED d\\u1EE5ng \",(0,n.jsx)(e.code,{children:\"spark-submit\"}),\" tr\\xEAn comand line, ch\\u1EC9 c\\u1EA7n thay \",(0,n.jsx)(e.code,{children:\"--master\"}),\" \\u0111\\u1EBFn \\u0111\\u1ECBa ch\\u1EC9 c\\u1EE7a Kubernetes \",(0,n.jsx)(e.code,{children:\"k8s://\u003capi_server_host\u003e:\u003ck8s-apiserver-port\u003e\"})]}),`\n`,(0,n.jsx)(e.p,{children:\"V\\xED d\\u1EE5 \\u0111\\u1EC3 ch\\u1EA1y Spark Pi tr\\xEAn Cluster mode, h\\xE3y xem v\\xED d\\u1EE5 sau:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`$ bin/spark-submit \\\\\n   --master k8s://https://\u003ck8s-apiserver-host\u003e:\u003ck8s-apiserver-port\u003e \\\\\n   --deploy-mode cluster \\\\\n   --name spark-pi \\\\\n   --class org.apache.spark.examples.SparkPi \\\\\n   --conf spark.executor.instances=5 \\\\\n   --conf spark.kubernetes.container.image=\u003cspark-image\u003e \\\\\n   local:///path/to/examples.jar\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Ch\\xFA \\xFD l\\xE0 \",(0,n.jsx)(e.code,{children:\"k8s://https://\"}),\" m\\xECnh kh\\xF4ng vi\\u1EBFt nh\\u1EA7m \\u0111\\xE2u nh\\xE9.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Nhu c\\u1EA7u \\u0111\\u1EC3 c\\xF3 th\\u1EC3 submit m\\u1ED9t lo\\u1EA1t jobs h\\xE0ng ng\\xE0y, team s\\u1EED d\\u1EE5ng \",(0,n.jsx)(e.strong,{children:(0,n.jsx)(e.a,{href:\"https://livy.incubator.apache.org/\",children:\"Apache Livy\"})}),\" tr\\xEAn Kubernetes, v\\u1EDBi ki\\u1EBFn tr\\xFAc nh\\u01B0 d\\u01B0\\u1EDBi \\u0111\\xE2y:\"]}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-1.png\",alt:\"\"})}),`\n`,(0,n.jsx)(e.p,{children:\"Team s\\u1EED d\\u1EE5ng Livy, \\u0111\\xE2y l\\xE0 m\\u1ED9t service cho ph\\xE9p t\\u01B0\\u01A1ng t\\xE1c v\\u1EDBi Spark Cluster th\\xF4ng qua RESTful API. Livy \\u0111\\xE3 t\\u1EEBng \\u0111\\u01B0\\u1EE3c s\\u1EED d\\u1EE5ng tr\\xEAn EMR, \\u1EDF Kubernetes ch\\u1EC9 c\\u1EA7n deploy Livy th\\xF4ng qua Helm m\\u1ED9t c\\xE1ch d\\u1EC5 d\\xE0ng. Xem th\\xEAm c\\xE1ch c\\xE0i \\u0111\\u1EB7t Livy \\u1EDF \\u0111\\xE2y. \\u0110\\u1EC3 trigger Livy c\\xF3 nhi\\u1EC1u c\\xE1ch, team s\\u1EED d\\u1EE5ng Airflow nh\\u01B0 l\\xE0 m\\u1ED9t scheduler, c\\xF3 nhi\\u1EC1u lo\\u1EA1i DAGs t\\xF9y v\\xE0o t\\xEDnh ch\\u1EA5t c\\u1EE7a m\\u1ED7i Jobs, c\\xE1c DAG s\\u1EBD trigger Livy, theo d\\xF5i tr\\u1EA1ng th\\xE1i c\\u1EE7a Jobs \\u0111\\xF3 c\\u0169ng th\\xF4ng qua API, retry ho\\u1EB7c alert khi c\\u1EA7n thi\\u1EBFt. DAG c\\u0169ng c\\xF3 nhi\\u1EC7m v\\u1EE5 ki\\u1EC3m tra d\\u1EEF li\\u1EC7u (data validation) k\\u1EBFt qu\\u1EA3 \\u0111\\u1EA7u ra (output) cho m\\u1ED7i jobs.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Tuy nhi\\xEAn l\\u1EA1i c\\xF3 m\\u1ED9t s\\u1ED1 \\u0111i\\u1EC3m h\\u1EA1n ch\\u1EBF nh\\u01B0 do delay t\\u1EEB Airflow Scheduler, Livy c\\u0169ng d\\u1EC5 b\\u1ECB stuck. N\\u1EBFu m\\u1ED9t jobs ch\\u1EA1y l\\xE2u nh\\u01B0ng Livy b\\u1ECB restart th\\xEC Jobs \\u0111\\xF3 c\\u0169ng b\\u1ECB \\u1EA3nh h\\u01B0\\u1EDFng theo. Team quy\\u1EBFt \\u0111\\u1ECBnh n\\xE2ng c\\u1EA5p.\"}),`\n`,(0,n.jsx)(e.h1,{children:\"3. Spark on Kubernetes - Spark Operator\"}),`\n`,(0,n.jsx)(e.p,{children:\"Sau khi \\u0111\\xE1nh gi\\xE1 kh\\u1EA3 n\\u0103ng c\\u1EE7a Spark Operator b\\u1EDFi GCP Google, team quy\\u1EBFt \\u0111\\u1ECBnh \\u0111i \\u0111\\u1EBFn phi\\xEAn b\\u1EA3n 2.0 c\\u1EE7a architecture. C\\xE1c th\\xE0nh ph\\u1EA7n s\\u1EBD nh\\u01B0 h\\xECnh d\\u01B0\\u1EDBi \\u0111\\xE2y:\"}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-2-operator.png\",alt:\"\"})}),`\n`,(0,n.jsx)(e.p,{children:\"\\u1EDE ki\\u1EBFn tr\\xFAc tr\\xEAn, vai tr\\xF2 c\\u1EE7a Data Engineer s\\u1EBD l\\xE0:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsxs)(e.li,{children:[\"(1) generate ra \",(0,n.jsx)(e.strong,{children:\"Spark Jobs Artifacts\"}),\" v\\xE0 commit/push v\\xE0o m\\u1ED9t Repo tr\\xEAn Git. Spark Jobs Artifacts s\\u1EBD c\\xF3 d\\u1EA1ng nh\\u01B0 v\\xED d\\u1EE5 n\\xE0y, c\\xF3 th\\u1EC3 hi\\u1EC3u \\u0111\\xE2y l\\xE0 m\\u1ED9t specs \\u0111\\u1EC3 Spark Operator c\\xF3 th\\u1EC3 submit v\\xE0 qu\\u1EA3n l\\xFD Jobs tr\\xEAn namespace c\\u1EE7a m\\xECnh. C\\xF3 2 lo\\u1EA1i CRDs c\\u1EE7a Spark Operator sinh ra \\u0111\\u1EC3 qu\\u1EA3n l\\xFD l\\xE0 \",(0,n.jsx)(e.code,{children:\"SparkApplication\"}),\" v\\xE0 \",(0,n.jsx)(e.code,{children:\"ScheduledSparkApplication\"}),\".\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"(2) \",(0,n.jsx)(e.strong,{children:\"Spark Submit Worker\"}),\" l\\xE0 m\\u1ED9t Pod ch\\u1EA1y tr\\xEAn Kubernetes, c\\xF3 nhi\\u1EC7m v\\u1EE5 \\u0111\\u1ECDc/sync nh\\u1EEFng g\\xEC tr\\xEAn Git v\\xE0 apply v\\xE0o Kubernetes th\\xF4ng qua Kubernetes API (ho\\u1EA1t \\u0111\\u1ED9ng gi\\u1ED1ng nh\\u01B0 \",(0,n.jsx)(e.code,{children:\"kubectl apply -f\"}),\").\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"(3) \",(0,n.jsx)(e.strong,{children:\"Spark Operator\"}),\" nh\\u01B0 m\\u1ECDi Operator kh\\xE1c, s\\u1EBD l\\u1EAFng nghe/\\u0111\\u1ECDc CRDs \\u0111\\u01B0\\u1EE3c submit v\\xE0o cluster, s\\u1EBD specify, running, v\\xE0 c\\u1EADp nh\\u1EADt status c\\u1EE7a c\\xE1c Spark application. T\\u1EEB m\\u1ED9t \",(0,n.jsx)(e.code,{children:\"SparkApplication\"}),\" Spark Operator s\\u1EBD d\\u1EF1ng m\\u1ED9t POD driver, POD driver s\\u1EBD request th\\xEAm t\\u1EEB Kubernetes \\u0111\\u1EC3 d\\u1EF1ng th\\xEAm c\\xE1c POD executor, \\u0111\\u1EBFn khi n\\xE0o Spark Jobs th\\u1EF1c hi\\u1EC7n xong s\\u1EBD t\\u1EF1 \\u0111\\u1ED9ng terminate c\\xE1c pod n\\xE0y. Logs s\\u1EBD \\u0111\\u01B0\\u1EE3c l\\u01B0u gi\\u1EEF \\u1EDF S3 bucket.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"(4) \",(0,n.jsx)(e.strong,{children:\"Spark History Server\"}),\" s\\u1EBD render logs t\\u1EEB S3 bucket, gi\\xFAp team engineer d\\u1EC5 d\\xE0ng h\\u01A1n trong vi\\u1EC7c traceback l\\u1EA1i c\\xE1c jobs c\\u0169 \\u0111\\xE3 finish.\"]}),`\n`,(0,n.jsxs)(e.li,{children:[\"(5) \",(0,n.jsx)(e.strong,{children:\"Spark Jobs UI\"}),\" l\\xE0 m\\u1ED9t Web UI \\u0111\\u1EC3 qu\\u1EA3n l\\xFD t\\u1EA5t c\\u1EA3 c\\xE1c Spark Jobs tr\\xEAn Git, ki\\u1EC3m tra tr\\u1EA1ng th\\xE1i c\\u1EE7a m\\u1ED7i Jobs tr\\xEAn Cluster, monitor, data validation c\\u0169ng nh\\u01B0 backfill.\"]}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"H\\xE3y t\\xECm hi\\u1EC3u xem m\\u1ED9t s\\u1ED1 th\\xE0nh ph\\u1EA7n ch\\xEDnh \\u0111\\xF3ng vai tr\\xF2 g\\xEC nh\\xE9.\"}),`\n`,(0,n.jsx)(e.h2,{children:\"3.1. Spark Operator\"}),`\n`,(0,n.jsx)(e.p,{children:\"Spark Operator l\\xE0 m\\u1ED9t Kubernetes Operator \\u0111\\u01B0\\u1EE3c thi\\u1EBFt k\\u1EBF cho Spark nh\\u1EB1m m\\u1EE5c \\u0111\\xEDch x\\xE1c \\u0111\\u1ECBnh v\\xE0 th\\u1EF1c thi c\\xE1c Spark applications d\\u1EC5 d\\xE0ng nh\\u01B0 c\\xE1c workloads kh\\xE1c tr\\xEAn Kubernetes, b\\u1EB1ng c\\xE1ch s\\u1EED d\\u1EE5ng v\\xE0 qu\\u1EA3n l\\xFD m\\u1ED9t Kubernetes custom resources (CRD) \\u0111\\u1EC3 specifying, running, v\\xE0 update status c\\u1EE7a Spark applications.\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"\\u0110\\u1EC3 t\\xECm hi\\u1EC3u th\\xEAm b\\u1EA1n c\\xF3 th\\u1EC3 xem qua v\\u1EC1 \",(0,n.jsx)(e.a,{href:\"https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/design.md\",children:\"Design\"}),\", \",(0,n.jsx)(e.a,{href:\"https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md\",children:\"API Specification\"}),\", v\\xE0 \",(0,n.jsx)(e.a,{href:\"https://github.com/GoogleCloudPlatform/spark-on-k8s-operator/blob/master/docs/user-guide.md\",children:\"User Guide\"}),\" tr\\xEAn Github.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"V\\xED d\\u1EE5 \\u0111\\u1EC3 c\\xE0i \\u0111\\u1EB7t Spark Operator tr\\xEAn namespace \",(0,n.jsx)(e.code,{children:\"spark-jobs\"}),\" th\\xF4ng qua Helm chart, \\u1EDF \\u0111\\xE2y m\\xECnh b\\u1EADt t\\xEDnh n\\u0103ng \",(0,n.jsx)(e.code,{children:\"webhook\"}),\". T\\xF9y v\\xE0o h\\u1EC7 th\\u1ED1ng qu\\u1EA3n l\\xFD c\\u1EE7a b\\u1EA1n m\\xE0 c\\xF3 th\\u1EC3 c\\xE0i \\u0111\\u1EB7t th\\xF4ng quan FluxCD hay ArgoCD, \\u1EDF \\u0111\\xE2y m\\xECnh s\\u1EED d\\u1EE5ng \",(0,n.jsx)(e.code,{children:\"helm\"}),\" cli \\u0111\\u01A1n gi\\u1EA3n cho vi\\u1EC7c minh h\\u1ECDa:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`helm repo add spark-operator https://googlecloudplatform.github.io/spark-on-k8s-operator\nhelm install spark-operator \\\\\n   spark-operator/spark-operator \\\\\n   --namespace spark-jobs \\\\\n   --set sparkJobNamespace=spark-jobs \\\\\n   --set webhook.enable=true\n`})}),`\n`,(0,n.jsx)(e.h2,{children:\"3.2. Spark Submit Worker\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"M\\u1ED9t \",(0,n.jsx)(e.code,{children:\"SparkApplication\"}),\" c\\xF3 v\\u1EC1 c\\u01A1 b\\u1EA3n l\\xE0 m\\u1ED9t resource CRD, c\\xF3 th\\u1EC3 \\u0111\\u01B0\\u1EE3c apply v\\xE0o cluster b\\u1EB1ng \",(0,n.jsx)(e.code,{children:\"kubectl\"}),\", nh\\u01B0 v\\xED d\\u1EE5 d\\u01B0\\u1EDBi \\u0111\\xE2y:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`# spark-pi.yaml\n---\napiVersion: 'sparkoperator.k8s.io/v1beta2'\nkind: SparkApplication\nmetadata:\n  name: pyspark-pi\n  namespace: spark-jobs\nspec:\n  type: Python\n  pythonVersion: '3'\n  mode: cluster\n  image: 'gcr.io/spark-operator/spark-py:v3.1.1'\n  imagePullPolicy: Always\n  mainApplicationFile: local:///opt/spark/examples/src/main/python/pi.py\n  sparkVersion: '3.1.1'\n  restartPolicy:\n    type: OnFailure\n    onFailureRetries: 3\n    onFailureRetryInterval: 10\n    onSubmissionFailureRetries: 5\n    onSubmissionFailureRetryInterval: 20\n  driver:\n    cores: 1\n    coreLimit: '1200m'\n    memory: '512m'\n    labels:\n      version: 3.1.1\n    serviceAccount: spark\n  executor:\n    cores: 1\n    instances: 1\n    memory: '512m'\n    labels:\n      version: 3.1.1\n`})}),`\n`,(0,n.jsx)(e.p,{children:\"\\u0110\\u1EC3 submit SparkPi n\\xE0y v\\xE0o Kubernetes, b\\u1EA1n ch\\u1EC9 c\\u1EA7n s\\u1EED d\\u1EE5ng:\"}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-bash\",children:`kubectl apply -f spark-pi.yaml\nkubectl get sparkapp\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"\\u0110\\u1EC3 t\\u1EF1 \\u0111\\u1ED9ng h\\xF3a, \",(0,n.jsx)(e.strong,{children:\"Spark Submit Worker\"}),\" l\\xE0 m\\u1ED9t Cronjob Pod \\u0111\\u1EC3 \\u0111\\u1ECBnh k\\u1EF3 (~5ph) sync v\\u1EDBi Git Repo v\\xE0 apply m\\u1ECDi spark app d\\u01B0\\u1EDBi d\\u1EA1ng c\\xE1c file YAML v\\xE0 m\\u1ECDi thay \\u0111\\u1ED5i l\\xEAn cluster. C\\xF3 2 d\\u1EA1ng artifacts m\\xE0 Spark Submit qu\\u1EA3n l\\xFD l\\xE0 \",(0,n.jsx)(e.code,{children:\"SparkApplication\"}),\" v\\xE0 \",(0,n.jsx)(e.code,{children:\"ScheduledSparkApplication\"}),\" nh\\u01B0 \\u0111\\xE3 n\\xF3i \\u1EDF tr\\xEAn.\"]}),`\n`,(0,n.jsxs)(e.p,{children:[\"Vi\\u1EC7c qu\\u1EA3n l\\xFD c\\xE1c Spark Application d\\u01B0\\u1EDBi d\\u1EA1ng YAML specs c\\xF2n gi\\xFAp c\\xF3 th\\xEAm m\\u1ED9t s\\u1ED1 l\\u1EE3i \\xEDch c\\u1EE7a \",(0,n.jsx)(e.strong,{children:\"GitOps\"}),\": m\\u1ECDi thay \\u0111\\u1ED5i \\u0111\\u1EC1u \\u0111\\u01B0\\u1EE3c Git Versioning, ph\\xE2n quy\\u1EC1n tr\\xEAn Git, review thay \\u0111\\u1ED5i, approve ho\\u1EB7c reject thay \\u0111\\u1ED5i, d\\u1EC5 d\\xE0ng rollback b\\u1EB1ng c\\xE1ch revert git, \\u2026\"]}),`\n`,(0,n.jsx)(e.h2,{children:\"3.3. Spark Jobs UI\"}),`\n`,(0,n.jsx)(e.p,{children:\"Spark Jobs UI hay Spark Jobs Dashboard l\\xE0 m\\u1ED9t Web UI \\u0111\\u1EC3 qu\\u1EA3n l\\xFD Spark Jobs v\\xE0 artifacts \\u0111\\u01B0\\u1EE3c generated ho\\u1EB7c customized b\\u1EDFi engineers. Dashboard \\u0111\\u01B0\\u1EE3c vi\\u1EBFt b\\u1EB1ng Typescript v\\xE0 Next.js, g\\u1ED3m m\\u1ED9t s\\u1ED1 t\\xEDnh n\\u0103ng c\\u01A1 b\\u1EA3n nh\\u01B0:\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Li\\u1EC7t k\\xEA m\\u1ECDi Spark Jobs artifacts\"}),`\n`,(0,n.jsx)(e.li,{children:\"Xem n\\u1ED9i dung c\\u1EE7a t\\u1EEBng Spark Application YAML files\"}),`\n`,(0,n.jsxs)(e.li,{children:[\"Xem th\\xF4ng tin status c\\u1EE7a m\\u1ED7i Scheduled Spark Application nh\\u01B0 l\\xE0 \",(0,n.jsx)(e.code,{children:\"scheduleStatus\"}),\", \",(0,n.jsx)(e.code,{children:\"lastRun\"}),\", \",(0,n.jsx)(e.code,{children:\"nextRun\"}),\", ...\"]}),`\n`,(0,n.jsx)(e.li,{children:\"Ki\\u1EC3m tra nhanh d\\u1EEF li\\u1EC7u output (basic data validation) cho m\\u1ED7i jobs theo interval c\\u1EE7a Jobs \\u0111\\xF3. V\\xED d\\u1EE5 m\\u1ED9t jobs theo ng\\xE0y (daily), UI s\\u1EBD ki\\u1EC3m tra m\\u1ED7i ng\\xE0y xem c\\xF3 data c\\u1EE7a ng\\xE0y h\\xF4m \\u0111\\xF3 c\\xF3 h\\u1EE3p l\\u1EC7 kh\\xF4ng.\"}),`\n`,(0,n.jsx)(e.li,{children:\"Th\\u1ED1ng k\\xEA c\\u01A1 b\\u1EA3n nh\\u01B0 s\\u1ED1 Jobs \\u0111ang ch\\u1EA1y, \\u0111ang pending, s\\u1ED1 l\\u01B0\\u1EE3ng Jobs l\\u1ED7i, resources (CPU/Memory) s\\u1EED d\\u1EE5ng, \\u2026\"}),`\n`,(0,n.jsx)(e.li,{children:\"Backfill: c\\xF3 th\\u1EC3 trigger ch\\u1EA1y l\\u1EA1i cho m\\u1ED9t ho\\u1EB7c nhi\\u1EC1u jobs, m\\u1ED9t ng\\xE0y ho\\u1EB7c nhi\\u1EC1u ng\\xE0y.\"}),`\n`]}),`\n`,(0,n.jsx)(e.p,{children:\"H\\xE3y xem m\\u1ED9t s\\u1ED1 screenshot d\\u01B0\\u1EDBi \\u0111\\xE2y \\u0111\\u1EC3 c\\xF3 c\\xE1i h\\xECnh c\\u1EE5 th\\u1EC3 h\\u01A1n:\"}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-3.png\",alt:\"Fossil Spark UI\"})}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-4.png\",alt:\"Data Validation\"})}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-5.png\",alt:\"Backfill: trigger \\u0111\\u1EC3 ch\\u1EA1y l\\u1EA1i Jobs cho m\\u1ED9t ho\\u1EB7c m\\u1ED9t s\\u1ED1 ng\\xE0y c\\u1EE5 th\\u1EC3 trong qu\\xE1 kh\\u1EE9\"})}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-6.png\",alt:\"C\\xF3 th\\u1EC3 custom m\\u1ED9t s\\u1ED1 config l\\xFAc ch\\u1EA1y backfill, nh\\u01B0 resources, s\\u1ED1 l\\u01B0\\u1EE3ng executor, spark version, ...\"})}),`\n`,(0,n.jsx)(e.h2,{children:\"3.4. Spark History Server\"}),`\n`,(0,n.jsxs)(e.p,{children:[\"Spark History Server l\\xE0 m\\u1ED9t Spark Web UI c\\xF3 s\\u1EB5n c\\u1EE7a Spark, d\\xF9ng \\u0111\\u1EC3 monitor tr\\u1EA1ng th\\xE1i v\\xE0 t\\xE0i nguy\\xEAn s\\u1EED d\\u1EE5ng cho Spark App. Spark History Server \\u0111\\u01B0\\u1EE3c d\\u1EF1ng l\\xEAn \\u0111\\u1EC3 \\u0111\\u1ECDc l\\u1EA1i logs c\\u1EE7a c\\xE1c Jobs \\u0111\\xE3 ho\\xE0n th\\xE0nh tr\\u01B0\\u1EDBc \\u0111\\xF3 l\\u01B0u tr\\xEAn S3 bucket. M\\u1ED7i \",(0,n.jsx)(e.code,{children:\"SparkApplication\"}),\" s\\u1EBD \\u0111\\u01B0\\u1EE3c config \\u0111\\u1EC3 push Spark events l\\xEAn S3:\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`spec:\n  sparkConf:\n    'spark.eventLog.enabled': 'true'\n    'spark.eventLog.dir': 's3a://fossil-spark/logs/'\n`})}),`\n`,(0,n.jsxs)(e.p,{children:[\"Spark History Server c\\u0169ng c\\xF3 th\\u1EC3 \\u0111\\u01B0\\u1EE3c c\\xE0i \\u0111\\u1EB7t th\\xF4ng qua \",(0,n.jsx)(e.a,{href:\"https://artifacthub.io/packages/helm/spot/spark-history-server\",children:\"this Helm Chart\"}),\", ch\\u1EC9 c\\u1EA7n tr\\u1ECF \\u0111\\xFAng \\u0111\\u01B0\\u1EDDng d\\u1EABn c\\u1EE7a \",(0,n.jsx)(e.code,{children:\"logDirectory\"}),\" v\\xE0o \\u0111\\xFAng v\\u1ECB tr\\xED S3 bucket m\\xE0 Spark \\u0111\\xE3 g\\u1EEDi l\\xEAn.\"]}),`\n`,(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:\"language-yaml\",children:`helm repo add stable https://kubernetes-charts.storage.googleapis.com\nhelm install stable/spark-history-server \\\\\n--namespace spark-jobs \\\\\n--set enableS3=true \\\\\n--set logDirectory=s3a://fossil-spark/logs/\n`})}),`\n`,(0,n.jsx)(e.p,{children:(0,n.jsx)(e.img,{src:\"/media/2022/03/spark-k8s-7.png\",alt:\"Untitled\"})}),`\n`,(0,n.jsx)(e.h1,{children:\"4. Performance Tuning on Kubernetes\"}),`\n`,(0,n.jsxs)(e.p,{children:[`C\\xF3 r\\u1EA5t nhi\\u1EC1u t\\u1ED1i \\u01B0u \\u0111\\u01B0\\u1EE3c \\u0111\\u01B0\\u1EE3c th\\u1EF1c hi\\u1EC7n do t\\xEDnh ch\\u1EA5t Spark tr\\xEAn Kubernetes + AWS s\\u1EBD c\\xF3 ch\\xFAt kh\\xE1c bi\\u1EC7t v\\u1EDBi Spark tr\\xEAn YARN.\nM\\u1ED9t s\\u1ED1 c\\xF3 th\\u1EC3 k\\u1EC3 \\u0111\\u1EBFn m\\xE0 b\\u1EA1n c\\xF3 th\\u1EC3 xem th\\xEAm \\u1EDF \\u0111\\xE2y\n`,(0,n.jsx)(e.a,{href:\"/2021/04/spark-kubernetes-performance-tuning.html\",children:\"Spark on Kubernetes Performance Tuning\"}),\" ho\\u1EB7c d\\u1EC5 d\\xE0ng t\\xECm ki\\u1EBFm tr\\xEAn Google:\"]}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"Using Volcano Scheduler for Gang schedule\"}),`\n`,(0,n.jsx)(e.li,{children:\"Using Kryo serialization\"}),`\n`,(0,n.jsx)(e.li,{children:\"Ignoring Data Locality because of S3 data source.\"}),`\n`,(0,n.jsx)(e.li,{children:\"I/O for S3\"}),`\n`,(0,n.jsx)(e.li,{children:\"Tuning Java\"}),`\n`,(0,n.jsx)(e.li,{children:\"Enabled Dynamic Allocation and Dynamic Allocation Shuffle File Tracking\"}),`\n`,(0,n.jsx)(e.li,{children:\"Using Kubernetes Node Spot instance for the executors.\"}),`\n`]}),`\n`,(0,n.jsx)(e.h1,{children:\"5. K\\u1EBFt\"}),`\n`,(0,n.jsx)(e.p,{children:\"Nh\\u01B0 v\\u1EADy l\\xE0 m\\u1ECDi ng\\u01B0\\u1EDDi \\u0111\\xE3 c\\xF3 th\\u1EC3 h\\xECnh dung \\u0111\\u01B0\\u1EE3c c\\xE1ch m\\xE0 team Data Platform t\\u1EA1i Fossil s\\u1EED d\\u1EE5ng v\\u1EADn h\\xE0nh Apache Spark tr\\xEAn Kubernetes.\"}),`\n`,(0,n.jsx)(e.p,{children:\"Do c\\xF3 nhi\\u1EC1u chi ti\\u1EBFt, nhi\\u1EC1u v\\u1EA5n \\u0111\\u1EC1 k\\u1EF9 thu\\u1EADt, c\\xE1ch c\\xE0i \\u0111\\u1EB7t, c\\xE1ch t\\u1ED1i \\u01B0u, \\u2026 m\\xE0 m\\xECnh kh\\xF3 c\\xF3 th\\u1EC3 \\u0111\\u1EC1 c\\u1EADp h\\u1EBFt \\u0111\\u01B0\\u1EE3c, do \\u0111\\xF3 b\\xE0i vi\\u1EBFt ch\\u1EC9 d\\u1EEBng l\\u1EA1i \\u1EDF t\\xEDnh ch\\u1EA5t gi\\u1EDBi thi\\u1EC7u t\\u1ED5ng qu\\xE1t. M\\xECnh s\\u1EBD c\\u1ED1 g\\u1EAFng chi ti\\u1EBFt h\\xF3a c\\xE1c v\\u1EA5n \\u0111\\u1EC1 \\u1EDF c\\xE1c b\\xE0i vi\\u1EBFt kh\\xE1c n\\u1EBFu c\\xF3 th\\u1EC3 trong t\\u01B0\\u01A1ng lai.\"}),`\n`,(0,n.jsx)(\"div\",{className:\"bg-emerald-600 p-5\",children:(0,n.jsxs)(e.p,{children:[`B\\xE0i vi\\u1EBFt c\\u0169ng \\u0111\\u01B0\\u1EE3c \\u0111\\u0103ng t\\u1EA1i\n`,(0,n.jsx)(\"a\",{href:\"https://blog.duyet.net/2022/03/spark-kubernetes-at-fossil\",children:\"duyet.net\"}),\".\"]})}),`\n`,(0,n.jsx)(\"div\",{className:\"bg-blue-100 border-t border-b border-blue-500\",children:(0,n.jsxs)(e.p,{children:[`Hi\\u1EC7n t\\u1EA1i Fossil Cloud Data \\u0111ang open cho c\\xE1c v\\u1ECB tr\\xED (Sr) Data Engineer,\n`,(0,n.jsx)(\"a\",{href:\"https://sites.google.com/fossil.com/fossil-vietnam/careers/jobs\",target:\"_blank\",children:\"xem th\\xEAm JD t\\u1EA1i \\u0111\\xE2y\"}),`\nho\\u1EB7c g\\u1EEDi CV c\\u1EE7a b\\u1EA1n v\\u1EC1 email `,(0,n.jsx)(\"strong\",{children:\"lvduyet (at) fossil.com\"}),\" \\u0111\\u1EC3 c\\xF9ng trao \\u0111\\u1ED5i th\\xEAm nh\\xE9.\"]})}),`\n`,(0,n.jsx)(e.h1,{children:\"6. References\"}),`\n`,(0,n.jsxs)(e.ul,{children:[`\n`,(0,n.jsx)(e.li,{children:\"https://kubernetes.io\"}),`\n`,(0,n.jsx)(e.li,{children:\"https://spark.apache.org\"}),`\n`,(0,n.jsx)(e.li,{children:\"https://airflow.apache.org\"}),`\n`,(0,n.jsx)(e.li,{children:\"https://livy.incubator.apache.org\"}),`\n`,(0,n.jsx)(e.li,{children:\"https://github.com/GoogleCloudPlatform/spark-on-k8s-operator\"}),`\n`,(0,n.jsx)(e.li,{children:\"https://kubernetes.io/docs/concepts/extend-kubernetes/operator\"}),`\n`]})]})}function f(r={}){let{wrapper:e}=r.components||{};return e?(0,n.jsx)(e,Object.assign({},r,{children:(0,n.jsx)(o,r)})):o(r)}var A=f;return y(x);})();\n;return Component;","toc":[],"frontMatter":{"readingTime":{"text":"13 min read","minutes":12.085,"time":725100,"words":2417},"slug":"spark-on-kubernetes-at-fossil","fileName":"2022-03-10-spark-on-kubernetes-at-fossil.md","title":"Spark on Kubernetes tại Fossil","authors":["duyet"],"date":"2022-03-10T00:00:00.000Z","tags":["engineering","data"],"summary":"Apache Spark được chọn làm công nghệ cho Batch layer bởi khả năng xử lý một lượng lớn data cùng một lúc. Ở thiết kế ban đầu, team data chọn sử dụng Apache Spark trên AWS EMR do có sẵn và triển khai nhanh chóng. Dần dần, AWS EMR bộc lộ một số điểm hạn chế trên môi trường Production. Trong bài viết này, mình sẽ nói về tại sao và làm thế nào team Data chuyển từ Spark trên AWS EMR sang Kubernetes.","layout":"PostLayout"}},"authorDetails":[{"readingTime":{"text":"1 min read","minutes":0.47,"time":28200,"words":94},"slug":["duyet"],"fileName":"duyet.md","name":"Duyet Le","avatar":"https://avatars.githubusercontent.com/u/5009534?v=4","occupation":"Data Engineer","company":"Fossil Vietnam","email":"lvduyet@fossil.com","twitter":"https://twitter.com/_duyet","linkedin":"https://www.linkedin.com/in/duyet","github":"https://github.com/duyet","date":null}],"prev":{"title":"1,234 days — Day 1 at Fossil","authors":["nga"],"date":"2020-02-27T00:00:00.000Z","tags":["life"],"summary":"A thousand-ish more days later, I could definitely testify to the jaded Day 1 philosophy by Amazon CEO Jeff Bezos: Every day here has felt just like Day 1.","layout":"PostLayout","slug":"1234"},"next":{"title":"Working From Home","authors":["phuong"],"date":"2022-07-11T00:00:00.000Z","tags":["management"],"summary":"Working From Home hiện đang là working style trending, nhưng liệu có hiệu quả?","layout":"PostLayout","slug":"working-from-home"}},"__N_SSG":true},"page":"/blog/[...slug]","query":{"slug":["spark-on-kubernetes-at-fossil"]},"buildId":"uAv3iUABIr6Ubl_-73ex7","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>