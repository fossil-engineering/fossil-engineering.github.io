<!DOCTYPE html><html lang="en"><head><meta charSet="utf-8"/><meta content="width=device-width, initial-scale=1" name="viewport"/><title>Apache Spark behind the scenes</title><meta name="robots" content="follow, index"/><meta name="description" content="Các bạn có thắc mắc sau khi submit 1 job cho Spark Cluster thì Spark sẽ làm những gì không? Cùng tìm hiểu với mình nhé."/><meta property="og:url" content="https://fossil-engineering.github.io/blog/apache-spark-behind-the-scienes"/><meta property="og:type" content="article"/><meta property="og:site_name" content="Fossil Engineering"/><meta property="og:description" content="Các bạn có thắc mắc sau khi submit 1 job cho Spark Cluster thì Spark sẽ làm những gì không? Cùng tìm hiểu với mình nhé."/><meta property="og:title" content="Apache Spark behind the scenes"/><meta property="og:image" content="https://fossil-engineering.github.io/static/img/twitter-card.png"/><meta name="twitter:card" content="summary_large_image"/><meta name="twitter:site" content=""/><meta name="twitter:title" content="Apache Spark behind the scenes"/><meta name="twitter:description" content="Các bạn có thắc mắc sau khi submit 1 job cho Spark Cluster thì Spark sẽ làm những gì không? Cùng tìm hiểu với mình nhé."/><meta name="twitter:image" content="https://fossil-engineering.github.io/static/img/twitter-card.png"/><meta property="article:published_time" content="2022-07-12T00:00:00.000Z"/><link rel="canonical" href="https://fossil-engineering.github.io/blog/apache-spark-behind-the-scienes"/><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "Article",
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://fossil-engineering.github.io/blog/apache-spark-behind-the-scienes"
  },
  "headline": "Apache Spark behind the scenes",
  "image": [
    {
      "@type": "ImageObject",
      "url": "https://fossil-engineering.github.io/static/img/twitter-card.png"
    }
  ],
  "datePublished": "2022-07-12T00:00:00.000Z",
  "dateModified": "2022-07-12T00:00:00.000Z",
  "author": [
    {
      "@type": "Person",
      "name": "Hung Tran"
    }
  ],
  "publisher": {
    "@type": "Organization",
    "name": "",
    "logo": {
      "@type": "ImageObject",
      "url": "https://fossil-engineering.github.ioundefined"
    }
  },
  "description": "Các bạn có thắc mắc sau khi submit 1 job cho Spark Cluster thì Spark sẽ làm những gì không? Cùng tìm hiểu với mình nhé."
}</script><meta name="next-head-count" content="19"/><link rel="apple-touch-icon" sizes="180x180" href="/static/favicons/apple-touch-icon.png"/><link rel="icon" type="image/png" sizes="32x32" href="/static/favicons/favicon-32x32.png"/><link rel="icon" type="image/png" sizes="16x16" href="/static/favicons/favicon-16x16.png"/><link rel="manifest" href="/static/favicons/site.webmanifest"/><link rel="mask-icon" href="/static/favicons/safari-pinned-tab.svg" color="#5bbad5"/><meta name="msapplication-TileColor" content="#2b5797"/><meta name="theme-color" content="#ffffff"/><link rel="alternate" type="application/rss+xml" href="/feed.xml"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"/><link rel="preconnect" href="https://rsms.me" crossorigin="anonymous"/><link rel="stylesheet" href="https://rsms.me/inter/inter.css"/><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.13.11/dist/katex.min.css" integrity="sha384-Um5gpz1odJg5Z4HAmzPtgZKdTBHZdw8S29IecapCSB31ligYPhHQZMIlWLYQGVoc" crossorigin="anonymous"/><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin /><link rel="preload" href="/_next/static/css/fa77ec408337cd38.css" as="style"/><link rel="stylesheet" href="/_next/static/css/fa77ec408337cd38.css" data-n-g=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/_next/static/chunks/polyfills-c67a75d1b6f99dc8.js"></script><script src="/_next/static/chunks/webpack-54ae5776470dcfe8.js" defer=""></script><script src="/_next/static/chunks/framework-109a728694328ca8.js" defer=""></script><script src="/_next/static/chunks/main-3d54289b1db19e6f.js" defer=""></script><script src="/_next/static/chunks/pages/_app-af73530b3e9d1b5f.js" defer=""></script><script src="/_next/static/chunks/459-f230713b90b0f34a.js" defer=""></script><script src="/_next/static/chunks/410-5f0c6f2fa70bc464.js" defer=""></script><script src="/_next/static/chunks/620-4ffca7d07d13ee0d.js" defer=""></script><script src="/_next/static/chunks/pages/blog/%5B...slug%5D-0a1bff3ee9d6b739.js" defer=""></script><script src="/_next/static/_xuPiwf0iXmMr_jdV40M4/_buildManifest.js" defer=""></script><script src="/_next/static/_xuPiwf0iXmMr_jdV40M4/_ssgManifest.js" defer=""></script><style data-href="https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap">@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuLyfMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuGKYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcCO3FwrK3iLTeHuS_fvQtMwCp50KnMw2boKoduKmMEVuFuYMZs.woff) format('woff')}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:400;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:600;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2JL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0460-052F,U+1C80-1C88,U+20B4,U+2DE0-2DFF,U+A640-A69F,U+FE2E-FE2F}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa0ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0301,U+0400-045F,U+0490-0491,U+04B0-04B1,U+2116}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2ZL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+1F00-1FFF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0370-03FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa2pL7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0102-0103,U+0110-0111,U+0128-0129,U+0168-0169,U+01A0-01A1,U+01AF-01B0,U+1EA0-1EF9,U+20AB}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa25L7W0Q5n-wU.woff2) format('woff2');unicode-range:U+0100-024F,U+0259,U+1E00-1EFF,U+2020,U+20A0-20AB,U+20AD-20CF,U+2113,U+2C60-2C7F,U+A720-A7FF}@font-face{font-family:'Inter';font-style:normal;font-weight:700;font-display:swap;src:url(https://fonts.gstatic.com/s/inter/v12/UcC73FwrK3iLTeHuS_fvQtMwCp50KnMa1ZL7W0Q5nw.woff2) format('woff2');unicode-range:U+0000-00FF,U+0131,U+0152-0153,U+02BB-02BC,U+02C6,U+02DA,U+02DC,U+2000-206F,U+2074,U+20AC,U+2122,U+2191,U+2193,U+2212,U+2215,U+FEFF,U+FFFD}</style></head><body class="antialiased text-black bg-white dark:bg-gray-900 dark:text-white"><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-5xl xl:px-0"><div class="flex flex-col justify-between h-screen"><header class="flex items-center justify-between py-10"><div><a aria-label="Fossil Engineering" href="/"><div class="flex items-center justify-between"><div class="mr-3 logo"><svg xmlns="http://www.w3.org/2000/svg" width="132.393" height="25.507" xml:space="preserve"><path d="M89.751 10.925c-4.768-1.529-6.842-2.877-6.486-5.096.342-2.201 2.729-2.07 5.047-1.89 2.291.192 4.158.701 5.52 1.148.025.018.105-.004.121-.082.121-.806.559-2.943.678-3.675.018-.091-.068-.136-.113-.147C91.729.428 89.182-.052 86.137.004c-5.703.099-8.354 2.396-8.678 7.192-.191 2.799 1.748 5.893 5.777 7.227 4.029 1.334 6.904 2.087 6.486 4.57-.369 2.104-2.85 2.342-5.539 2.187-2.355-.144-4.348-.705-5.834-1.156-.107-.032-.172.021-.197.119-.111.864-.424 3.071-.531 3.849-.004.104.084.188.129.198 1.859.445 5.15 1.07 9.197 1.07 5.473 0 8.312-2.347 8.631-6.841.247-3.487-1.395-6.067-5.827-7.494zM65.068 10.925c-4.771-1.529-6.839-2.877-6.485-5.096.344-2.201 2.729-2.07 5.04-1.89 2.292.192 4.16.701 5.517 1.148.039.018.096-.004.113-.082.139-.806.566-2.943.691-3.675a.139.139 0 0 0-.111-.147C67.04.428 64.494-.052 61.454.004 55.75.103 53.101 2.4 52.766 7.196c-.188 2.8 1.753 5.896 5.774 7.23 4.024 1.334 6.898 2.086 6.494 4.567-.367 2.105-2.846 2.342-5.539 2.188-2.366-.142-4.346-.707-5.842-1.156-.096-.032-.168.021-.188.117-.11.867-.425 3.073-.53 3.853-.003.102.075.188.124.196a40.142 40.142 0 0 0 9.191 1.07c5.478 0 8.31-2.347 8.632-6.843.256-3.486-1.387-6.066-5.814-7.493zM17.998.555H1.468a.157.157 0 0 0-.162.155v23.971c0 .088.064.16.162.16H6.96a.156.156 0 0 0 .155-.16V15.71c0-.082.072-.16.162-.16h9.525c.092 0 .164-.064.164-.15v-3.708a.165.165 0 0 0-.164-.165H7.277a.16.16 0 0 1-.162-.162V4.74c0-.085.072-.16.162-.16h10.861a.154.154 0 0 0 .156-.157L18.168.711c-.012-.08-.09-.156-.17-.156zM109.023.537h-5.666c-.1 0-.16.068-.16.156v23.991c0 .084.061.149.16.149h5.666c.09 0 .154-.065.154-.149V.693a.152.152 0 0 0-.154-.156zM133.536 20.742h-9.395a.16.16 0 0 1-.158-.156L123.981.732c0-.099-.066-.161-.16-.161h-5.658a.157.157 0 0 0-.162.161v23.951c0 .084.076.147.162.147h15.186c.088 0 .164-.063.168-.147l.182-3.772c-.002-.098-.065-.169-.163-.169zM35.363.026c-7.436 0-11.493 4.878-11.493 12.743 0 7.857 4.059 12.738 11.493 12.738 7.433 0 11.487-4.881 11.487-12.738C46.85 4.787 42.901.026 35.363.026zm0 21.462c-5.05 0-5.749-4.193-5.749-8.719 0-4.52.699-8.714 5.749-8.714 5.044 0 5.738 4.192 5.738 8.714 0 4.525-.694 8.719-5.738 8.719z"></path></svg></div></div></a></div><div class="flex items-center text-base leading-5"><div class="hidden sm:block"><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/blog">Blog</a><a class="p-1 font-medium text-gray-900 sm:p-4 dark:text-gray-100" href="/about">About</a></div><button aria-label="Toggle Dark Mode" type="button" class="w-8 h-8 p-1 ml-1 mr-1 rounded sm:ml-4"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path d="M17.293 13.293A8 8 0 016.707 2.707a8.001 8.001 0 1010.586 10.586z"></path></svg></button><div class="sm:hidden"><button type="button" class="w-8 h-8 py-1 ml-1 mr-1 rounded" aria-label="Toggle Menu"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" fill="currentColor" class="text-gray-900 dark:text-gray-100"><path fill-rule="evenodd" d="M3 5a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 10a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1zM3 15a1 1 0 011-1h12a1 1 0 110 2H4a1 1 0 01-1-1z" clip-rule="evenodd"></path></svg></button><div class="fixed w-full h-full top-24 right-0 bg-gray-200 dark:bg-gray-800 opacity-95 z-10 transform ease-in-out duration-300 translate-x-full"><button type="button" aria-label="toggle modal" class="fixed w-full h-full cursor-auto focus:outline-none"></button><nav class="fixed h-full mt-8"><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/blog">Blog</a></div><div class="px-12 py-4"><a class="text-2xl font-bold tracking-widest text-gray-900 dark:text-gray-100" href="/about">About</a></div></nav></div></div></div></header><main class="mb-auto"><div class="max-w-3xl px-4 mx-auto sm:px-6 xl:max-w-5xl xl:px-0"><article><div class="xl:divide-y xl:divide-gray-200 xl:dark:divide-gray-700"><header class="pt-6 xl:pb-6"><div class="space-y-1 text-center"><dl class="space-y-10"><div><dt class="sr-only">Published on</dt><dd class="text-base font-medium leading-6 text-gray-500 dark:text-gray-400"><time dateTime="2022-07-12T00:00:00.000Z">Tuesday, July 12, 2022</time></dd></div></dl><div><h1 class="text-3xl font-extrabold leading-9 tracking-tight text-gray-900 dark:text-gray-100 sm:text-4xl sm:leading-10 md:text-5xl md:leading-14">Apache Spark behind the scenes</h1></div></div></header><div class="pb-8 divide-y divide-gray-200 xl:divide-y-0 dark:divide-gray-700 xl:grid xl:grid-cols-4 xl:gap-x-6" style="grid-template-rows:auto 1fr"><dl class="pt-6 pb-10 xl:pt-11 xl:border-b xl:border-gray-200 xl:dark:border-gray-700"><dt class="sr-only">Authors</dt><dd><ul class="flex justify-center space-x-8 xl:block sm:space-x-12 xl:space-x-0 xl:space-y-8"><li class="flex items-center space-x-2"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%2738%27%20height=%2738%27/%3e"/></span><img alt="avatar" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" class="w-10 h-10 rounded-full" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="avatar" srcSet="https://avatars.githubusercontent.com/u/61528065?v=4?imwidth=48 1x, https://avatars.githubusercontent.com/u/61528065?v=4?imwidth=96 2x" src="https://avatars.githubusercontent.com/u/61528065?v=4?imwidth=96" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" class="w-10 h-10 rounded-full" loading="lazy"/></noscript></span><dl class="text-sm font-medium leading-5 whitespace-nowrap"><dt class="sr-only">Name</dt><dd class="text-gray-900 dark:text-gray-100"><a href="/author/hung">Hung Tran</a></dd><dt class="sr-only">Twitter</dt><dd><a target="_blank" rel="noopener noreferrer" href="https://github.com/hungtran150" class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400">@hungtran150</a></dd></dl></li></ul></dd></dl><div class="divide-y divide-gray-200 dark:divide-gray-700 xl:pb-0 xl:col-span-3 xl:row-span-2"><div class="pt-10 pb-8 prose dark:prose-dark max-w-none"><ul>
<li><a href="#overview">Overview</a></li>
<li><a href="#spark-architecture">Spark Architecture</a>
<ul>
<li><a href="#cluster-manager">Cluster Manager</a></li>
<li><a href="#driver">Driver</a>
<ul>
<li><a href="#sparkcontext">SparkContext</a></li>
<li><a href="#logical-execution-plan">Logical execution plan</a></li>
<li><a href="#dagscheduler">DagScheduler</a></li>
<li><a href="#taskscheduler">TaskScheduler</a></li>
<li><a href="#backendscheduler">BackendScheduler</a></li>
<li><a href="#blockmanager">BlockManager</a></li>
</ul>
</li>
<li><a href="#catalyst-optimizer">Catalyst Optimizer</a>
<ul>
<li><a href="#logical-plan">Logical Plan</a>
<ul>
<li><a href="#unresolved-logical-plan">Unresolved Logical Plan</a></li>
<li><a href="#analyzed-logical-plan">Analyzed Logical Plan</a></li>
<li><a href="#optimize-logical-plan">Optimize Logical Plan</a></li>
</ul>
</li>
<li><a href="#physical-plan">Physical plan</a>
<ul>
<li><a href="#operator">Operator</a></li>
<li><a href="#additional-rules">Additional Rules</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#executor">Executor</a></li>
</ul>
</li>
<li><a href="#references">References</a>
<br/>
<br/>
</li>
</ul>
<h1>Overview</h1>
<p>Có bao giờ bạn thắc mắc, sau khi bạn submit một app vào Spark cluster để thực hiện những tính toán hoặc biến đổi trên dữ liệu, thì Spark sẽ làm gì không?</p>
<p>Bài viết này mình sẽ chia sẻ tổng quan Spark hoạt động như thế nào.</p>
<h1>Spark Architecture</h1>
<p>Spark Architecture gồm những gì?</p>
<p><img src="/media/2022/07/spark-behind-1.png" alt=""/></p>
<p>Quan sát hình ta thấy Spark có 3 thành phần chính:</p>
<ol>
<li>Cluster Manager</li>
<li>Driver</li>
<li>Worker</li>
</ol>
<p>Thông thường Spark sẽ hoạt động với master node và nhiều worker node, giống với Hadoop master and slave node.</p>
<p>Dưới đây miêu tả chi tiết mỗi thành phần sẽ làm những gì.</p>
<h2>Cluster Manager</h2>
<p>Cluster manager là một platform mà chúng ta deploy hoặc chạy Spark trên đó lưu ý là chỉ với cluster mode (local mode mình sẽ không đề cập ở đây)</p>
<p>Có những kiểu cluster manager như sau:</p>
<ul>
<li>Kubernetes: Hiện tại, Spark ở Fossil được deploy trên Kubernetes (k8s một hệ thống open source dùng để tự động deploy, quản lý, mở rộng cho container)</li>
<li>Hadoop Yarn: Hệ thống quản lý Big data Hadoop</li>
<li>Standalone: Đây là kiểu được Spark hỗ trợ để tự dựng 1 cluster cơ bản một cách dễ dàng</li>
<li>Apache Mesos (Deprecated)</li>
</ul>
<h2>Driver</h2>
<p><img src="/media/2022/07/spark-behind-2.png" alt=""/></p>
<p>Spark driver là thành phần chính cho những Spark app, nó thường nằm ở master node (Standalone mode, Hadoop Yarn). Tuy nhiên ở Fossil Spark được deploy trên k8s nên mỗi lần client submit một spark app vào k8s cluster, k8s sẽ tạo nên một pod driver cho 1 spark app.</p>
<p>Sau khi Driver được tạo ra, thì nó sẽ chuyển đổi user application thành từng phần nhỏ được gọi là Job và task. Sau đó sẽ chịu trách nhiệm giao tiếp với quản lý tài nguyên để yêu cầu tài nguyên (executor) và phân bổ tài nguyên cho các executor, Driver sẽ quét qua Spark app code để biết được đâu là <strong>transformation</strong> đâu là <strong>action</strong> để tạo ra Spark Execution plan (Logical plan và Physical plan). Ngoài việc phân bổ tài nguyên và lên lịch Job cho Executor thực thi, Driver còn làm những nhiệm vụ khác như: Collect status của từng executor, Collect những executor metrics và hiển thị lên Spark UI.</p>
<p>Driver có rất nhiều thành phần.Một số thành phần chính bao gồm:</p>
<ul>
<li>SparkContext</li>
<li>Logical execution plan</li>
<li>DagScheduler</li>
<li>TaskScheduler</li>
<li>BackendScheduler</li>
<li>BlockManager</li>
</ul>
<p>Đây là flow xử lý RDD</p>
<p>Còn với DataFrame hoặc SQL hoặc DataSet ta sẽ có 1 flow khác sử dụng Catalyst Optimizer</p>
<p>2 flow chỉ khác nhau ở chỗ Logical plan và physical plan.</p>
<ul>
<li>Với RDD Logical Execution plan sẽ không đi qua Catalyst Optimize mà sẽ đi thẳng vào DagScheduler để thực thi.</li>
<li>Riêng với DataFrame, SQL hoặc DataSet sẽ đi qua Catalyst Optimize trước khi vào DagScheduler.</li>
</ul>
<h3>SparkContext</h3>
<p>Spark Context là main entrypoint của tất cả các thành phần trong Spark, thành phần chính của tất cả Spark App.</p>
<h3>Logical execution plan</h3>
<p>Logical execution plan là 1 abstract của các bước chuyển đổi cần được thực hiện (Có bao nhiêu RDDs sẽ được tạo ra, bởi vì RDD imutable nên mỗi lần transform sẽ tạo ra 1 hoặc nhiều RDD mới tùy vào Narrow hoặc Wide transform) còn được gọi là RDD lineage. Như vậy Logical execution plan được tạo bởi từng transformation của từng RDD và lưu ở SparkContext.</p>
<h3>DagScheduler</h3>
<p>Sau khi Logical execution plan đã được tạo, khi có 1 action được gọi DagScheduler sẽ chuyển nó thành Physical execution plan (bằng cách sử dụng <strong>Job</strong> và <strong>Stage</strong>). Để phân biệt được đâu là method action đâu là method transform mình đã kiếm được 1 slide có những thông tin này cảm ơn vào tác giả có tên là Jeff Thomspon <a target="_blank" rel="noopener noreferrer" href="https://training.databricks.com/visualapi.pdf">link</a>.</p>
<ul>
<li>Job: Mỗi một job là 1 action trong Spark. Action sẽ thực hiện job trên cluster và return value lại cho Spark Driver.</li>
<li>Stage: Mỗi 1 job sẽ có nhiều stage. Số lượng stage sẽ phụ thuộc vào bạn thực hiện Narrow Transformation hoặc Wide Transformation. Tất cả Narrow Transformation (map, flatmap, …) sẽ được thực hiện trên 1 stage. Khác với Narrow, Wide Transformation sẽ tạo ra 1 stage mới điều này dẫn tới mỗi 1 stage sẽ có <strong>stage boundary</strong>. Mỗi 1 Stage Spark sẽ lưu data ở local disk.</li>
<li>Task: Mỗi 1 Stage sẽ có nhiều task, mỗi 1 task sẽ ứng với 1 partition.</li>
</ul>
<p>Nhiệm vụ của DagScheduler:</p>
<ul>
<li>Sẽ tính toán và tạo ra exection DAG (DAG của những stages) cho 1 job sau đó submits những stage đó cho <strong>TaskScheduler.</strong></li>
<li>Xác định preferred locations (Vị trí host, executor id) để run task, ngoài ra nó nó tracking RDD nào đã được cache để không recompute lại.</li>
<li>Xử lý failures, resumitted nguyên 1 stage nếu có 1 task nào đó bị lỗi.</li>
</ul>
<p>DagScheduler sử dụng event driven architect, Nếu như có 1 job mới được submit thì DagScheduler sẽ đọc và thực hiện 1 cách tuần tự.</p>
<h3>TaskScheduler</h3>
<p>TaskScheduler sẽ nhận set of task đã được submit bởi <strong>DagScheduler</strong> cho từng stage, và có nhiệm vụ schedule và sending task cho worker hoặc executor thực hiện, retry nếu như bị lỗi.</p>
<h3>BackendScheduler</h3>
<p>BackendScheduler sẽ hỗ trợ nhiều loại cluster manager như: Hadoop-Yarn, Kubernetes, Apache Mesos.</p>
<p>Khi Spark app yêu cầu resource từ cluster manager để thực thi, nếu như <strong>BackendScheduler</strong> nhận được resource allocate bởi cluster manager, nó có thể start executor.</p>
<h3>BlockManager</h3>
<p><strong>BlockManager</strong> là nơi lưu trữ block of data dưới dạng key-value và chạy trên tất cả các node trong Spark App ví dụ như: Driver, Executor. Nó upload và fetch data block ở local và remote sử dụng nhiều kiểu lưu trữ như: memory, disk, off-heap.</p>
<ul>
<li>Nếu như Result trả về quá lớn, nó sẽ được persisted ở “memory + disk” được quản lý bởi <strong>BlockManager</strong>. Driver sẽ get result thông qua <strong>indirectResult (Storage location)</strong>. Khi nào cần Driver sẽ fetch nó qua HTTP.</li>
<li>Nếu như Result trả về nhỏ hơn 10mb (<code>spark.akka.frameSize = 10MB</code>). Nó sẽ được gửi về thẳng driver thông qua <strong>directResult</strong>.</li>
</ul>
<h2>Catalyst Optimizer</h2>
<p><img src="/media/2022/07/spark-behind-3.png" alt=""/></p>
<p>Mình sẽ nói sơ Catalyst Optimizer là gì. Catalyst Optimizer là Core của SQL query và DataFrame, Catalyst Optimizer hỗ trợ <strong>Rules-based optimization</strong> (Tất cả các Ruled để Optimize và Analysis) và <strong>Cost-base optimization</strong> (Sử dụng các Rule của Rules-based để optimize dựa vào thống kê và tính toán). Vậy Catalyst sẽ làm như thế nào? Catalyst sử dụng cấu trúc dữ liệu cây để xây dựng query plan hoặc xây dựng cây của những expression, các node của cây được định nghĩa bằng Scala như là subclass của TreeNode class (Ví dụ: 1 node của cây có thể là datatype dạng int, hoặc function add cộng 2 số int). Catalyst sử dụng Rules optimize được định nghĩa sẵn để biến đổi một cây thành 1 cây tối ưu hơn (lát nữa mình sẽ có ví dụ).</p>
<h3>Logical Plan</h3>
<h4>Unresolved Logical Plan</h4>
<p>Theo như mình tìm hiểu thì khi code Spark app của chúng ta đúng syntax và valid nhưng tên của các column và các bảng trong query hoặc trong dataframe của các bạn bị sai hoặc không tồn tại nếu đúng thì Spark sẽ raise lỗi ngay vào lúc này, nhưng Spark vẫn sẽ tạo ra một <strong>Unresolved Logic Plan/Parsed Logical Plan</strong> (Blank Logical plan).</p>
<h4>Analyzed Logical Plan</h4>
<p>Sau khi Spark tạo ra Unresolved Logical Plan sẽ đi qua componen Catalog. Catalog là nơi chứa các metadata của dataFrame, Spark table, Dataset. Spark sẽ sử dụng những Rule ở Catalyst và Catalog sẽ giúp Spark check những column name, data type để resolve và sẽ tạo ra <strong>Logical plan/Analyzed Logical plan</strong>.</p>
<h4>Optimize Logical Plan</h4>
<p>Sau khi Logical plan được tạo ra sẽ qua 1 bước là Logical Optimize, ở bước này Catalyst sẽ optimize lại logical plan của chúng ta.</p>
<p>Ví dụ: mình có 2 Dataframes:</p>
<p><img src="/media/2022/07/spark-behind-4.png" alt=""/></p>
<p><img src="/media/2022/07/spark-behind-5.png" alt=""/></p>
<p>Bây giờ mình sẽ thực hiện các bước transform như sau:</p>
<div class="relative"><pre><code class="language-python">df3 = df1.join(df2, df1.dep_id == df2.dep_id, &quot;inner&quot;)
        .filter(df1.salary &gt;= 4000)
        .withColumn(&quot;salary&quot;, df1.salary*3)
        .filter((df1.firstname == &quot;Duyet&quot;) | (df1.firstname == &quot;Duong&quot;))
</code></pre></div>
<p>Đầu tiên mình sẽ join Dataframe lại với nhau. Filter những ai có salary &gt;= 4000, Sau đó nhân 3 giá trị của cột salary ở df1, sau đó filter firstname là Duyet hoặc Duong. Đây sẽ là expected bahavior mà chúng ta muốn. Bây giờ chúng ta sẽ xem Logical plan mà Spark sẽ tạo ra nhé</p>
<div class="relative"><pre><code class="language-python">df3.explain(True)
</code></pre></div>
<p><img src="/media/2022/07/spark-behind-6.png" alt=""/></p>
<p>Như các bạn thấy Unresolved logical plan sẽ không hiển thị các data type của data</p>
<p><img src="/media/2022/07/spark-behind-7.png" alt=""/></p>
<p>Sau khi Analyzed Spark sẽ biết được các data type của các column trên data.</p>
<p>Bây giờ hãy đọc cái plan này nha. Để đọc plan của Spark chúng ta sẽ đọc ngược, đọc từ dưới lên trên. Đầu tiên sẽ là</p>
<ul>
<li>Join 2 dataframe</li>
<li>Filter Salary &gt;= 4000</li>
<li>Project (Select) các cột đồng thời cột salary * 3</li>
<li>Bước cuối cùng sẽ filer lại những người có tên là Duyet hoặc Duong</li>
</ul>
<p>Rõ ràng các bước transform này không tối ưu. Nếu là mình sẽ viết 1 cách tối ưu hơn bằng cách filter trước những điều kiện có sẵn rồi mới join 2 data sau cùng, nhưng đây là ví dụ để thấy được Spark Catalyst sẽ optimize như thế nào. Mình tiếp tục nhìn xem Optimize Logical Plan sau khi Spark Optimize nhé.</p>
<p><img src="/media/2022/07/spark-behind-8.png" alt=""/></p>
<p>Sau khi Optimized chúng ta thấy các step đã được tự động thay đổi và được gộp lại chung với nhau</p>
<ul>
<li>Đầu tiên sẽ filter df2 cột dep_id not null</li>
<li>Tiếp theo sẽ gộp filter Salary &gt;= 4000 và filter firstname và cột dep_id not null cho df1</li>
<li>Cuối cùng mới join</li>
</ul>
<p>Rõ ràng là đã Optimize hơn các bước Expect behavior.</p>
<p>Tuy nhiên mình có 1 lưu ý là Catalyst Optimizer chỉ có DataFrame hoặc DataSet hoặc SQL query mới có thể chạy qua 1 số Spark Feature như Catalyst Optimizer hoặc Tungsten Optimizer. Nếu các bạn sử dụng RDD để process các bạn phải tự tối ưu.</p>
<p>Sau khi có Optimize Logical plan, ở Physical planning Spark sẽ generate ra nhiều physical plan. Cost model sẽ tính cost của từng Physical plan sao cho tối ưu nhất và chọn nó, Ngoài ra <strong>Cost-base optimization</strong> sẽ chọn cách join sao cho phù hợp nhất với data.</p>
<h3>Physical plan</h3>
<p><img src="/media/2022/07/spark-behind-9.png" alt=""/></p>
<p>Ở physcal plan sẽ có 2 bước:</p>
<p>Bước 1:</p>
<p>Tạo ra những step sử dụng các strategies ứng với mỗi node của logical plan, ví dụ:</p>
<ul>
<li>Trong logical plan: JOIN</li>
<li>Trong Physical plan: SortMergeJoin, BroadcastHashJoin</li>
</ul>
<p>Bước 2:</p>
<p>Final version plan sẽ được thực hiện, tạo ra RDD code</p>
<h4>Operator</h4>
<ul>
<li>FileScan: miêu tả việc đọc data từ 1 format.</li>
<li>Exchange: miêu tả việc shuffle - physical data movement trên cluster.</li>
<li>HashAggregate, SortAggregate, ObjectHashAggregate: Miêu tả data aggregation.</li>
<li>SortMergeJoin: Miêu tả việc join 2 dataframe, Exchange và sort thường sẽ xảy ra trước khi SortMergeJoin nhưng không nhất thiết phải xảy ra.</li>
<li>BroadcastHashJoin: Miêu tả việc join 2 dataframe.</li>
</ul>
<h4>Additional Rules</h4>
<p>Ngoài Operator còn có những rule như:</p>
<ul>
<li>EnsureRequirements</li>
<li>ReuseExchange</li>
<li>…</li>
</ul>
<p>Sau khi chọn ra được Physical plan phù hợp. Code generator sẽ generate Java code Binary và sẽ được thự hiện trên các worker.</p>
<h2>Executor</h2>
<p>Spark app thường sẽ start 1 hoặc nhiều Executor để thực hiện task.</p>
<p>Mặc định (Static Allocation of Executors) với chế độ này Executor thường sẽ chạy cho tới khi nào Spark app kết thúc. Việc này dẫn đến không tối ưu về resource</p>
<p>Khác với static (Dynamic Allocation). các Executor sẽ tự động remove khi thực hiện xong task. Việc này sẽ tiết kiệm resource cho cluster.</p>
<p>Ngoài ra Executor report hearbeat và các metrics của task về cho driver.</p>
<p>Executor có thể run multiple task song song và tuần tự, và tracking những task đang chạy.</p>
<h1>References</h1>
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/JerryLead/SparkInternals">https://github.com/JerryLead/SparkInternals</a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://www.slideshare.net/databricks/physical-plans-in-spark-sql">https://www.slideshare.net/databricks/physical-plans-in-spark-sql</a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html">https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html</a></p>
<p><a target="_blank" rel="noopener noreferrer" href="https://books.japila.pl/apache-spark-internals/">https://books.japila.pl/apache-spark-internals/</a></p>
<p>Spark Submit Conference</p></div><div class="pt-6 pb-6 text-sm text-gray-700 dark:text-gray-300"><a target="_blank" rel="nofollow" href="https://mobile.twitter.com/search?q=https%3A%2F%2Ffossil-engineering.github.io%2Fblog%2Fapache-spark-behind-the-scienes">Discuss on Twitter</a> • <a target="_blank" rel="noopener noreferrer" href="https://github.com/fossil-engineering/fossil-engineering.github.io/blob/master/data/blog/2022-07-12-apache-spark-behind-the-scienes.md">View on GitHub</a></div></div><footer><div class="text-sm font-medium leading-5 divide-gray-200 xl:divide-y dark:divide-gray-700 xl:col-start-1 xl:row-start-2"><div class="py-4 xl:py-8"><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Tags</h2><div class="flex flex-wrap"><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/engineering">engineering</a><a class="mr-3 text-sm font-medium uppercase text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/tags/data">data</a></div></div><div class="flex justify-between py-4 xl:block xl:space-y-8 xl:py-8"><div><h2 class="text-xs tracking-wide text-gray-500 uppercase dark:text-gray-400">Previous Article</h2><div class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400"><a href="/blog/working-from-home">Working From Home</a></div></div></div></div><div class="pt-4 xl:pt-8"><a class="text-primary-500 hover:text-primary-600 dark:hover:text-primary-400" href="/blog">← Back to the blog</a></div></footer></div></div></article></div></main><footer><div class="flex flex-col items-center mt-16"><div class="flex mb-3 space-x-4"><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="mailto:people@fossil.com"><span class="sr-only">mail</span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 20 20" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M2.003 5.884 10 9.882l7.997-3.998A2 2 0 0 0 16 4H4a2 2 0 0 0-1.997 1.884z"></path><path d="m18 8.118-8 4-8-4V14a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8.118z"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://github.com/fossil-engineering"><span class="sr-only">github</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"></path></svg></a><a class="text-sm text-gray-500 transition hover:text-gray-600" target="_blank" rel="noopener noreferrer" href="https://www.linkedin.com/company/fossilvietnamcareers/"><span class="sr-only">linkedin</span><svg viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg" class="fill-current text-gray-700 dark:text-gray-200 hover:text-blue-500 dark:hover:text-blue-400 h-6 w-6"><path d="M20.447 20.452h-3.554v-5.569c0-1.328-.027-3.037-1.852-3.037-1.853 0-2.136 1.445-2.136 2.939v5.667H9.351V9h3.414v1.561h.046c.477-.9 1.637-1.85 3.37-1.85 3.601 0 4.267 2.37 4.267 5.455v6.286zM5.337 7.433a2.062 2.062 0 0 1-2.063-2.065 2.064 2.064 0 1 1 2.063 2.065zm1.782 13.019H3.555V9h3.564v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.227.792 24 1.771 24h20.451C23.2 24 24 23.227 24 22.271V1.729C24 .774 23.2 0 22.222 0h.003z"></path></svg></a></div><div class="flex mb-2 space-x-2 text-sm text-gray-500 dark:text-gray-400"><div>© 2022</div><div> • </div><a href="/">Fossil Engineering</a></div><div class="mb-8 text-sm text-gray-500 dark:text-gray-400"><a target="_blank" rel="noopener noreferrer" href="https://github.com/timlrx/tailwind-nextjs-starter-blog">Tailwind Nextjs Theme</a></div></div></footer></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"post":{"mdxSource":"var Component=(()=\u003e{var s=Object.create;var r=Object.defineProperty;var p=Object.getOwnPropertyDescriptor;var g=Object.getOwnPropertyNames;var u=Object.getPrototypeOf,m=Object.prototype.hasOwnProperty;var k=(i,n)=\u003e()=\u003e(n||i((n={exports:{}}).exports,n),n.exports),y=(i,n)=\u003e{for(var c in n)r(i,c,{get:n[c],enumerable:!0})},l=(i,n,c,h)=\u003e{if(n\u0026\u0026typeof n==\"object\"||typeof n==\"function\")for(let a of g(n))!m.call(i,a)\u0026\u0026a!==c\u0026\u0026r(i,a,{get:()=\u003en[a],enumerable:!(h=p(n,a))||h.enumerable});return i};var v=(i,n,c)=\u003e(c=i!=null?s(u(i)):{},l(n||!i||!i.__esModule?r(c,\"default\",{value:i,enumerable:!0}):c,i)),S=i=\u003el(r({},\"__esModule\",{value:!0}),i);var o=k((z,t)=\u003e{t.exports=_jsx_runtime});var x={};y(x,{default:()=\u003eD,frontmatter:()=\u003eb});var e=v(o()),b={title:\"Apache Spark behind the scenes\",authors:[\"hung\"],date:\"2022-07-12\",tags:[\"engineering\",\"data\"],summary:\"C\\xE1c b\\u1EA1n c\\xF3 th\\u1EAFc m\\u1EAFc sau khi submit 1 job cho Spark Cluster th\\xEC Spark s\\u1EBD l\\xE0m nh\\u1EEFng g\\xEC kh\\xF4ng? C\\xF9ng t\\xECm hi\\u1EC3u v\\u1EDBi m\\xECnh nh\\xE9.\",layout:\"PostLayout\"};function d(i){let n=Object.assign({ul:\"ul\",li:\"li\",a:\"a\",h1:\"h1\",p:\"p\",img:\"img\",ol:\"ol\",h2:\"h2\",strong:\"strong\",h3:\"h3\",code:\"code\",h4:\"h4\",pre:\"pre\"},i.components);return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#overview\",children:\"Overview\"})}),`\n`,(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.a,{href:\"#spark-architecture\",children:\"Spark Architecture\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#cluster-manager\",children:\"Cluster Manager\"})}),`\n`,(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.a,{href:\"#driver\",children:\"Driver\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#sparkcontext\",children:\"SparkContext\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#logical-execution-plan\",children:\"Logical execution plan\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#dagscheduler\",children:\"DagScheduler\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#taskscheduler\",children:\"TaskScheduler\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#backendscheduler\",children:\"BackendScheduler\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#blockmanager\",children:\"BlockManager\"})}),`\n`]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.a,{href:\"#catalyst-optimizer\",children:\"Catalyst Optimizer\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.a,{href:\"#logical-plan\",children:\"Logical Plan\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#unresolved-logical-plan\",children:\"Unresolved Logical Plan\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#analyzed-logical-plan\",children:\"Analyzed Logical Plan\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#optimize-logical-plan\",children:\"Optimize Logical Plan\"})}),`\n`]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.a,{href:\"#physical-plan\",children:\"Physical plan\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#operator\",children:\"Operator\"})}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#additional-rules\",children:\"Additional Rules\"})}),`\n`]}),`\n`]}),`\n`]}),`\n`]}),`\n`,(0,e.jsx)(n.li,{children:(0,e.jsx)(n.a,{href:\"#executor\",children:\"Executor\"})}),`\n`]}),`\n`]}),`\n`,(0,e.jsxs)(n.li,{children:[(0,e.jsx)(n.a,{href:\"#references\",children:\"References\"}),`\n`,(0,e.jsx)(\"br\",{}),`\n`,(0,e.jsx)(\"br\",{}),`\n`]}),`\n`]}),`\n`,(0,e.jsx)(n.h1,{children:\"Overview\"}),`\n`,(0,e.jsx)(n.p,{children:\"C\\xF3 bao gi\\u1EDD b\\u1EA1n th\\u1EAFc m\\u1EAFc, sau khi b\\u1EA1n submit m\\u1ED9t app v\\xE0o Spark cluster \\u0111\\u1EC3 th\\u1EF1c hi\\u1EC7n nh\\u1EEFng t\\xEDnh to\\xE1n ho\\u1EB7c bi\\u1EBFn \\u0111\\u1ED5i tr\\xEAn d\\u1EEF li\\u1EC7u, th\\xEC Spark s\\u1EBD l\\xE0m g\\xEC kh\\xF4ng?\"}),`\n`,(0,e.jsx)(n.p,{children:\"B\\xE0i vi\\u1EBFt n\\xE0y m\\xECnh s\\u1EBD chia s\\u1EBB t\\u1ED5ng quan Spark ho\\u1EA1t \\u0111\\u1ED9ng nh\\u01B0 th\\u1EBF n\\xE0o.\"}),`\n`,(0,e.jsx)(n.h1,{children:\"Spark Architecture\"}),`\n`,(0,e.jsx)(n.p,{children:\"Spark Architecture g\\u1ED3m nh\\u1EEFng g\\xEC?\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-1.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"Quan s\\xE1t h\\xECnh ta th\\u1EA5y Spark c\\xF3 3 th\\xE0nh ph\\u1EA7n ch\\xEDnh:\"}),`\n`,(0,e.jsxs)(n.ol,{children:[`\n`,(0,e.jsx)(n.li,{children:\"Cluster Manager\"}),`\n`,(0,e.jsx)(n.li,{children:\"Driver\"}),`\n`,(0,e.jsx)(n.li,{children:\"Worker\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"Th\\xF4ng th\\u01B0\\u1EDDng Spark s\\u1EBD ho\\u1EA1t \\u0111\\u1ED9ng v\\u1EDBi master node v\\xE0 nhi\\u1EC1u worker node, gi\\u1ED1ng v\\u1EDBi Hadoop master and slave node.\"}),`\n`,(0,e.jsx)(n.p,{children:\"D\\u01B0\\u1EDBi \\u0111\\xE2y mi\\xEAu t\\u1EA3 chi ti\\u1EBFt m\\u1ED7i th\\xE0nh ph\\u1EA7n s\\u1EBD l\\xE0m nh\\u1EEFng g\\xEC.\"}),`\n`,(0,e.jsx)(n.h2,{children:\"Cluster Manager\"}),`\n`,(0,e.jsx)(n.p,{children:\"Cluster manager l\\xE0 m\\u1ED9t platform m\\xE0 ch\\xFAng ta deploy ho\\u1EB7c ch\\u1EA1y Spark tr\\xEAn \\u0111\\xF3 l\\u01B0u \\xFD l\\xE0 ch\\u1EC9 v\\u1EDBi cluster mode (local mode m\\xECnh s\\u1EBD kh\\xF4ng \\u0111\\u1EC1 c\\u1EADp \\u1EDF \\u0111\\xE2y)\"}),`\n`,(0,e.jsx)(n.p,{children:\"C\\xF3 nh\\u1EEFng ki\\u1EC3u cluster manager nh\\u01B0 sau:\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"Kubernetes: Hi\\u1EC7n t\\u1EA1i, Spark \\u1EDF Fossil \\u0111\\u01B0\\u1EE3c deploy tr\\xEAn Kubernetes (k8s m\\u1ED9t h\\u1EC7 th\\u1ED1ng open source d\\xF9ng \\u0111\\u1EC3 t\\u1EF1 \\u0111\\u1ED9ng deploy, qu\\u1EA3n l\\xFD, m\\u1EDF r\\u1ED9ng cho container)\"}),`\n`,(0,e.jsx)(n.li,{children:\"Hadoop Yarn: H\\u1EC7 th\\u1ED1ng qu\\u1EA3n l\\xFD Big data Hadoop\"}),`\n`,(0,e.jsx)(n.li,{children:\"Standalone: \\u0110\\xE2y l\\xE0 ki\\u1EC3u \\u0111\\u01B0\\u1EE3c Spark h\\u1ED7 tr\\u1EE3 \\u0111\\u1EC3 t\\u1EF1 d\\u1EF1ng 1 cluster c\\u01A1 b\\u1EA3n m\\u1ED9t c\\xE1ch d\\u1EC5 d\\xE0ng\"}),`\n`,(0,e.jsx)(n.li,{children:\"Apache Mesos (Deprecated)\"}),`\n`]}),`\n`,(0,e.jsx)(n.h2,{children:\"Driver\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-2.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"Spark driver l\\xE0 th\\xE0nh ph\\u1EA7n ch\\xEDnh cho nh\\u1EEFng Spark app, n\\xF3 th\\u01B0\\u1EDDng n\\u1EB1m \\u1EDF master node (Standalone mode, Hadoop Yarn). Tuy nhi\\xEAn \\u1EDF Fossil Spark \\u0111\\u01B0\\u1EE3c deploy tr\\xEAn k8s n\\xEAn m\\u1ED7i l\\u1EA7n client submit m\\u1ED9t spark app v\\xE0o k8s cluster, k8s s\\u1EBD t\\u1EA1o n\\xEAn m\\u1ED9t pod driver cho 1 spark app.\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"Sau khi Driver \\u0111\\u01B0\\u1EE3c t\\u1EA1o ra, th\\xEC n\\xF3 s\\u1EBD chuy\\u1EC3n \\u0111\\u1ED5i user application th\\xE0nh t\\u1EEBng ph\\u1EA7n nh\\u1ECF \\u0111\\u01B0\\u1EE3c g\\u1ECDi l\\xE0 Job v\\xE0 task. Sau \\u0111\\xF3 s\\u1EBD ch\\u1ECBu tr\\xE1ch nhi\\u1EC7m giao ti\\u1EBFp v\\u1EDBi qu\\u1EA3n l\\xFD t\\xE0i nguy\\xEAn \\u0111\\u1EC3 y\\xEAu c\\u1EA7u t\\xE0i nguy\\xEAn (executor) v\\xE0 ph\\xE2n b\\u1ED5 t\\xE0i nguy\\xEAn cho c\\xE1c executor, Driver s\\u1EBD qu\\xE9t qua Spark app code \\u0111\\u1EC3 bi\\u1EBFt \\u0111\\u01B0\\u1EE3c \\u0111\\xE2u l\\xE0 \",(0,e.jsx)(n.strong,{children:\"transformation\"}),\" \\u0111\\xE2u l\\xE0 \",(0,e.jsx)(n.strong,{children:\"action\"}),\" \\u0111\\u1EC3 t\\u1EA1o ra Spark Execution plan (Logical plan v\\xE0 Physical plan). Ngo\\xE0i vi\\u1EC7c ph\\xE2n b\\u1ED5 t\\xE0i nguy\\xEAn v\\xE0 l\\xEAn l\\u1ECBch Job cho Executor th\\u1EF1c thi, Driver c\\xF2n l\\xE0m nh\\u1EEFng nhi\\u1EC7m v\\u1EE5 kh\\xE1c nh\\u01B0: Collect status c\\u1EE7a t\\u1EEBng executor, Collect nh\\u1EEFng executor metrics v\\xE0 hi\\u1EC3n th\\u1ECB l\\xEAn Spark UI.\"]}),`\n`,(0,e.jsx)(n.p,{children:\"Driver c\\xF3 r\\u1EA5t nhi\\u1EC1u th\\xE0nh ph\\u1EA7n.M\\u1ED9t s\\u1ED1 th\\xE0nh ph\\u1EA7n ch\\xEDnh bao g\\u1ED3m:\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"SparkContext\"}),`\n`,(0,e.jsx)(n.li,{children:\"Logical execution plan\"}),`\n`,(0,e.jsx)(n.li,{children:\"DagScheduler\"}),`\n`,(0,e.jsx)(n.li,{children:\"TaskScheduler\"}),`\n`,(0,e.jsx)(n.li,{children:\"BackendScheduler\"}),`\n`,(0,e.jsx)(n.li,{children:\"BlockManager\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"\\u0110\\xE2y l\\xE0 flow x\\u1EED l\\xFD RDD\"}),`\n`,(0,e.jsx)(n.p,{children:\"C\\xF2n v\\u1EDBi DataFrame ho\\u1EB7c SQL ho\\u1EB7c DataSet ta s\\u1EBD c\\xF3 1 flow kh\\xE1c s\\u1EED d\\u1EE5ng Catalyst Optimizer\"}),`\n`,(0,e.jsx)(n.p,{children:\"2 flow ch\\u1EC9 kh\\xE1c nhau \\u1EDF ch\\u1ED7 Logical plan v\\xE0 physical plan.\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"V\\u1EDBi RDD Logical Execution plan s\\u1EBD kh\\xF4ng \\u0111i qua Catalyst Optimize m\\xE0 s\\u1EBD \\u0111i th\\u1EB3ng v\\xE0o DagScheduler \\u0111\\u1EC3 th\\u1EF1c thi.\"}),`\n`,(0,e.jsx)(n.li,{children:\"Ri\\xEAng v\\u1EDBi DataFrame, SQL ho\\u1EB7c DataSet s\\u1EBD \\u0111i qua Catalyst Optimize tr\\u01B0\\u1EDBc khi v\\xE0o DagScheduler.\"}),`\n`]}),`\n`,(0,e.jsx)(n.h3,{children:\"SparkContext\"}),`\n`,(0,e.jsx)(n.p,{children:\"Spark Context l\\xE0 main entrypoint c\\u1EE7a t\\u1EA5t c\\u1EA3 c\\xE1c th\\xE0nh ph\\u1EA7n trong Spark, th\\xE0nh ph\\u1EA7n ch\\xEDnh c\\u1EE7a t\\u1EA5t c\\u1EA3 Spark App.\"}),`\n`,(0,e.jsx)(n.h3,{children:\"Logical execution plan\"}),`\n`,(0,e.jsx)(n.p,{children:\"Logical execution plan l\\xE0 1 abstract c\\u1EE7a c\\xE1c b\\u01B0\\u1EDBc chuy\\u1EC3n \\u0111\\u1ED5i c\\u1EA7n \\u0111\\u01B0\\u1EE3c th\\u1EF1c hi\\u1EC7n (C\\xF3 bao nhi\\xEAu RDDs s\\u1EBD \\u0111\\u01B0\\u1EE3c t\\u1EA1o ra, b\\u1EDFi v\\xEC RDD imutable n\\xEAn m\\u1ED7i l\\u1EA7n transform s\\u1EBD t\\u1EA1o ra 1 ho\\u1EB7c nhi\\u1EC1u RDD m\\u1EDBi t\\xF9y v\\xE0o Narrow ho\\u1EB7c Wide transform) c\\xF2n \\u0111\\u01B0\\u1EE3c g\\u1ECDi l\\xE0 RDD lineage. Nh\\u01B0 v\\u1EADy Logical execution plan \\u0111\\u01B0\\u1EE3c t\\u1EA1o b\\u1EDFi t\\u1EEBng transformation c\\u1EE7a t\\u1EEBng RDD v\\xE0 l\\u01B0u \\u1EDF SparkContext.\"}),`\n`,(0,e.jsx)(n.h3,{children:\"DagScheduler\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"Sau khi Logical execution plan \\u0111\\xE3 \\u0111\\u01B0\\u1EE3c t\\u1EA1o, khi c\\xF3 1 action \\u0111\\u01B0\\u1EE3c g\\u1ECDi DagScheduler s\\u1EBD chuy\\u1EC3n n\\xF3 th\\xE0nh Physical execution plan (b\\u1EB1ng c\\xE1ch s\\u1EED d\\u1EE5ng \",(0,e.jsx)(n.strong,{children:\"Job\"}),\" v\\xE0 \",(0,e.jsx)(n.strong,{children:\"Stage\"}),\"). \\u0110\\u1EC3 ph\\xE2n bi\\u1EC7t \\u0111\\u01B0\\u1EE3c \\u0111\\xE2u l\\xE0 method action \\u0111\\xE2u l\\xE0 method transform m\\xECnh \\u0111\\xE3 ki\\u1EBFm \\u0111\\u01B0\\u1EE3c 1 slide c\\xF3 nh\\u1EEFng th\\xF4ng tin n\\xE0y c\\u1EA3m \\u01A1n v\\xE0o t\\xE1c gi\\u1EA3 c\\xF3 t\\xEAn l\\xE0 Jeff Thomspon \",(0,e.jsx)(n.a,{href:\"https://training.databricks.com/visualapi.pdf\",children:\"link\"}),\".\"]}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"Job: M\\u1ED7i m\\u1ED9t job l\\xE0 1 action trong Spark. Action s\\u1EBD th\\u1EF1c hi\\u1EC7n job tr\\xEAn cluster v\\xE0 return value l\\u1EA1i cho Spark Driver.\"}),`\n`,(0,e.jsxs)(n.li,{children:[\"Stage: M\\u1ED7i 1 job s\\u1EBD c\\xF3 nhi\\u1EC1u stage. S\\u1ED1 l\\u01B0\\u1EE3ng stage s\\u1EBD ph\\u1EE5 thu\\u1ED9c v\\xE0o b\\u1EA1n th\\u1EF1c hi\\u1EC7n Narrow Transformation ho\\u1EB7c Wide Transformation. T\\u1EA5t c\\u1EA3 Narrow Transformation (map, flatmap, \\u2026) s\\u1EBD \\u0111\\u01B0\\u1EE3c th\\u1EF1c hi\\u1EC7n tr\\xEAn 1 stage. Kh\\xE1c v\\u1EDBi Narrow, Wide Transformation s\\u1EBD t\\u1EA1o ra 1 stage m\\u1EDBi \\u0111i\\u1EC1u n\\xE0y d\\u1EABn t\\u1EDBi m\\u1ED7i 1 stage s\\u1EBD c\\xF3 \",(0,e.jsx)(n.strong,{children:\"stage boundary\"}),\". M\\u1ED7i 1 Stage Spark s\\u1EBD l\\u01B0u data \\u1EDF local disk.\"]}),`\n`,(0,e.jsx)(n.li,{children:\"Task: M\\u1ED7i 1 Stage s\\u1EBD c\\xF3 nhi\\u1EC1u task, m\\u1ED7i 1 task s\\u1EBD \\u1EE9ng v\\u1EDBi 1 partition.\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"Nhi\\u1EC7m v\\u1EE5 c\\u1EE7a DagScheduler:\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsxs)(n.li,{children:[\"S\\u1EBD t\\xEDnh to\\xE1n v\\xE0 t\\u1EA1o ra exection DAG (DAG c\\u1EE7a nh\\u1EEFng stages) cho 1 job sau \\u0111\\xF3 submits nh\\u1EEFng stage \\u0111\\xF3 cho \",(0,e.jsx)(n.strong,{children:\"TaskScheduler.\"})]}),`\n`,(0,e.jsx)(n.li,{children:\"X\\xE1c \\u0111\\u1ECBnh preferred locations (V\\u1ECB tr\\xED host, executor id) \\u0111\\u1EC3 run task, ngo\\xE0i ra n\\xF3 n\\xF3 tracking RDD n\\xE0o \\u0111\\xE3 \\u0111\\u01B0\\u1EE3c cache \\u0111\\u1EC3 kh\\xF4ng recompute l\\u1EA1i.\"}),`\n`,(0,e.jsx)(n.li,{children:\"X\\u1EED l\\xFD failures, resumitted nguy\\xEAn 1 stage n\\u1EBFu c\\xF3 1 task n\\xE0o \\u0111\\xF3 b\\u1ECB l\\u1ED7i.\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"DagScheduler s\\u1EED d\\u1EE5ng event driven architect, N\\u1EBFu nh\\u01B0 c\\xF3 1 job m\\u1EDBi \\u0111\\u01B0\\u1EE3c submit th\\xEC DagScheduler s\\u1EBD \\u0111\\u1ECDc v\\xE0 th\\u1EF1c hi\\u1EC7n 1 c\\xE1ch tu\\u1EA7n t\\u1EF1.\"}),`\n`,(0,e.jsx)(n.h3,{children:\"TaskScheduler\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"TaskScheduler s\\u1EBD nh\\u1EADn set of task \\u0111\\xE3 \\u0111\\u01B0\\u1EE3c submit b\\u1EDFi \",(0,e.jsx)(n.strong,{children:\"DagScheduler\"}),\" cho t\\u1EEBng stage, v\\xE0 c\\xF3 nhi\\u1EC7m v\\u1EE5 schedule v\\xE0 sending task cho worker ho\\u1EB7c executor th\\u1EF1c hi\\u1EC7n, retry n\\u1EBFu nh\\u01B0 b\\u1ECB l\\u1ED7i.\"]}),`\n`,(0,e.jsx)(n.h3,{children:\"BackendScheduler\"}),`\n`,(0,e.jsx)(n.p,{children:\"BackendScheduler s\\u1EBD h\\u1ED7 tr\\u1EE3 nhi\\u1EC1u lo\\u1EA1i cluster manager nh\\u01B0: Hadoop-Yarn, Kubernetes, Apache Mesos.\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"Khi Spark app y\\xEAu c\\u1EA7u resource t\\u1EEB cluster manager \\u0111\\u1EC3 th\\u1EF1c thi, n\\u1EBFu nh\\u01B0 \",(0,e.jsx)(n.strong,{children:\"BackendScheduler\"}),\" nh\\u1EADn \\u0111\\u01B0\\u1EE3c resource allocate b\\u1EDFi cluster manager, n\\xF3 c\\xF3 th\\u1EC3 start executor.\"]}),`\n`,(0,e.jsx)(n.h3,{children:\"BlockManager\"}),`\n`,(0,e.jsxs)(n.p,{children:[(0,e.jsx)(n.strong,{children:\"BlockManager\"}),\" l\\xE0 n\\u01A1i l\\u01B0u tr\\u1EEF block of data d\\u01B0\\u1EDBi d\\u1EA1ng key-value v\\xE0 ch\\u1EA1y tr\\xEAn t\\u1EA5t c\\u1EA3 c\\xE1c node trong Spark App v\\xED d\\u1EE5 nh\\u01B0: Driver, Executor. N\\xF3 upload v\\xE0 fetch data block \\u1EDF local v\\xE0 remote s\\u1EED d\\u1EE5ng nhi\\u1EC1u ki\\u1EC3u l\\u01B0u tr\\u1EEF nh\\u01B0: memory, disk, off-heap.\"]}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsxs)(n.li,{children:[\"N\\u1EBFu nh\\u01B0 Result tr\\u1EA3 v\\u1EC1 qu\\xE1 l\\u1EDBn, n\\xF3 s\\u1EBD \\u0111\\u01B0\\u1EE3c persisted \\u1EDF \\u201Cmemory + disk\\u201D \\u0111\\u01B0\\u1EE3c qu\\u1EA3n l\\xFD b\\u1EDFi \",(0,e.jsx)(n.strong,{children:\"BlockManager\"}),\". Driver s\\u1EBD get result th\\xF4ng qua \",(0,e.jsx)(n.strong,{children:\"indirectResult (Storage location)\"}),\". Khi n\\xE0o c\\u1EA7n Driver s\\u1EBD fetch n\\xF3 qua HTTP.\"]}),`\n`,(0,e.jsxs)(n.li,{children:[\"N\\u1EBFu nh\\u01B0 Result tr\\u1EA3 v\\u1EC1 nh\\u1ECF h\\u01A1n 10mb (\",(0,e.jsx)(n.code,{children:\"spark.akka.frameSize = 10MB\"}),\"). N\\xF3 s\\u1EBD \\u0111\\u01B0\\u1EE3c g\\u1EEDi v\\u1EC1 th\\u1EB3ng driver th\\xF4ng qua \",(0,e.jsx)(n.strong,{children:\"directResult\"}),\".\"]}),`\n`]}),`\n`,(0,e.jsx)(n.h2,{children:\"Catalyst Optimizer\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-3.png\",alt:\"\"})}),`\n`,(0,e.jsxs)(n.p,{children:[\"M\\xECnh s\\u1EBD n\\xF3i s\\u01A1 Catalyst Optimizer l\\xE0 g\\xEC. Catalyst Optimizer l\\xE0 Core c\\u1EE7a SQL query v\\xE0 DataFrame, Catalyst Optimizer h\\u1ED7 tr\\u1EE3 \",(0,e.jsx)(n.strong,{children:\"Rules-based optimization\"}),\" (T\\u1EA5t c\\u1EA3 c\\xE1c Ruled \\u0111\\u1EC3 Optimize v\\xE0 Analysis) v\\xE0 \",(0,e.jsx)(n.strong,{children:\"Cost-base optimization\"}),\" (S\\u1EED d\\u1EE5ng c\\xE1c Rule c\\u1EE7a Rules-based \\u0111\\u1EC3 optimize d\\u1EF1a v\\xE0o th\\u1ED1ng k\\xEA v\\xE0 t\\xEDnh to\\xE1n). V\\u1EADy Catalyst s\\u1EBD l\\xE0m nh\\u01B0 th\\u1EBF n\\xE0o? Catalyst s\\u1EED d\\u1EE5ng c\\u1EA5u tr\\xFAc d\\u1EEF li\\u1EC7u c\\xE2y \\u0111\\u1EC3 x\\xE2y d\\u1EF1ng query plan ho\\u1EB7c x\\xE2y d\\u1EF1ng c\\xE2y c\\u1EE7a nh\\u1EEFng expression, c\\xE1c node c\\u1EE7a c\\xE2y \\u0111\\u01B0\\u1EE3c \\u0111\\u1ECBnh ngh\\u0129a b\\u1EB1ng Scala nh\\u01B0 l\\xE0 subclass c\\u1EE7a TreeNode class (V\\xED d\\u1EE5: 1 node c\\u1EE7a c\\xE2y c\\xF3 th\\u1EC3 l\\xE0 datatype d\\u1EA1ng int, ho\\u1EB7c function add c\\u1ED9ng 2 s\\u1ED1 int). Catalyst s\\u1EED d\\u1EE5ng Rules optimize \\u0111\\u01B0\\u1EE3c \\u0111\\u1ECBnh ngh\\u0129a s\\u1EB5n \\u0111\\u1EC3 bi\\u1EBFn \\u0111\\u1ED5i m\\u1ED9t c\\xE2y th\\xE0nh 1 c\\xE2y t\\u1ED1i \\u01B0u h\\u01A1n (l\\xE1t n\\u1EEFa m\\xECnh s\\u1EBD c\\xF3 v\\xED d\\u1EE5).\"]}),`\n`,(0,e.jsx)(n.h3,{children:\"Logical Plan\"}),`\n`,(0,e.jsx)(n.h4,{children:\"Unresolved Logical Plan\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"Theo nh\\u01B0 m\\xECnh t\\xECm hi\\u1EC3u th\\xEC khi code Spark app c\\u1EE7a ch\\xFAng ta \\u0111\\xFAng syntax v\\xE0 valid nh\\u01B0ng t\\xEAn c\\u1EE7a c\\xE1c column v\\xE0 c\\xE1c b\\u1EA3ng trong query ho\\u1EB7c trong dataframe c\\u1EE7a c\\xE1c b\\u1EA1n b\\u1ECB sai ho\\u1EB7c kh\\xF4ng t\\u1ED3n t\\u1EA1i n\\u1EBFu \\u0111\\xFAng th\\xEC Spark s\\u1EBD raise l\\u1ED7i ngay v\\xE0o l\\xFAc n\\xE0y, nh\\u01B0ng Spark v\\u1EABn s\\u1EBD t\\u1EA1o ra m\\u1ED9t \",(0,e.jsx)(n.strong,{children:\"Unresolved Logic Plan/Parsed Logical Plan\"}),\" (Blank Logical plan).\"]}),`\n`,(0,e.jsx)(n.h4,{children:\"Analyzed Logical Plan\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"Sau khi Spark t\\u1EA1o ra Unresolved Logical Plan s\\u1EBD \\u0111i qua componen Catalog. Catalog l\\xE0 n\\u01A1i ch\\u1EE9a c\\xE1c metadata c\\u1EE7a dataFrame, Spark table, Dataset. Spark s\\u1EBD s\\u1EED d\\u1EE5ng nh\\u1EEFng Rule \\u1EDF Catalyst v\\xE0 Catalog s\\u1EBD gi\\xFAp Spark check nh\\u1EEFng column name, data type \\u0111\\u1EC3 resolve v\\xE0 s\\u1EBD t\\u1EA1o ra \",(0,e.jsx)(n.strong,{children:\"Logical plan/Analyzed Logical plan\"}),\".\"]}),`\n`,(0,e.jsx)(n.h4,{children:\"Optimize Logical Plan\"}),`\n`,(0,e.jsx)(n.p,{children:\"Sau khi Logical plan \\u0111\\u01B0\\u1EE3c t\\u1EA1o ra s\\u1EBD qua 1 b\\u01B0\\u1EDBc l\\xE0 Logical Optimize, \\u1EDF b\\u01B0\\u1EDBc n\\xE0y Catalyst s\\u1EBD optimize l\\u1EA1i logical plan c\\u1EE7a ch\\xFAng ta.\"}),`\n`,(0,e.jsx)(n.p,{children:\"V\\xED d\\u1EE5: m\\xECnh c\\xF3 2 Dataframes:\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-4.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-5.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"B\\xE2y gi\\u1EDD m\\xECnh s\\u1EBD th\\u1EF1c hi\\u1EC7n c\\xE1c b\\u01B0\\u1EDBc transform nh\\u01B0 sau:\"}),`\n`,(0,e.jsx)(n.pre,{children:(0,e.jsx)(n.code,{className:\"language-python\",children:`df3 = df1.join(df2, df1.dep_id == df2.dep_id, \"inner\")\n        .filter(df1.salary \u003e= 4000)\n        .withColumn(\"salary\", df1.salary*3)\n        .filter((df1.firstname == \"Duyet\") | (df1.firstname == \"Duong\"))\n`})}),`\n`,(0,e.jsx)(n.p,{children:\"\\u0110\\u1EA7u ti\\xEAn m\\xECnh s\\u1EBD join Dataframe l\\u1EA1i v\\u1EDBi nhau. Filter nh\\u1EEFng ai c\\xF3 salary \u003e= 4000, Sau \\u0111\\xF3 nh\\xE2n 3 gi\\xE1 tr\\u1ECB c\\u1EE7a c\\u1ED9t salary \\u1EDF df1, sau \\u0111\\xF3 filter firstname l\\xE0 Duyet ho\\u1EB7c Duong. \\u0110\\xE2y s\\u1EBD l\\xE0 expected bahavior m\\xE0 ch\\xFAng ta mu\\u1ED1n. B\\xE2y gi\\u1EDD ch\\xFAng ta s\\u1EBD xem Logical plan m\\xE0 Spark s\\u1EBD t\\u1EA1o ra nh\\xE9\"}),`\n`,(0,e.jsx)(n.pre,{children:(0,e.jsx)(n.code,{className:\"language-python\",children:`df3.explain(True)\n`})}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-6.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"Nh\\u01B0 c\\xE1c b\\u1EA1n th\\u1EA5y Unresolved logical plan s\\u1EBD kh\\xF4ng hi\\u1EC3n th\\u1ECB c\\xE1c data type c\\u1EE7a data\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-7.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"Sau khi Analyzed Spark s\\u1EBD bi\\u1EBFt \\u0111\\u01B0\\u1EE3c c\\xE1c data type c\\u1EE7a c\\xE1c column tr\\xEAn data.\"}),`\n`,(0,e.jsx)(n.p,{children:\"B\\xE2y gi\\u1EDD h\\xE3y \\u0111\\u1ECDc c\\xE1i plan n\\xE0y nha. \\u0110\\u1EC3 \\u0111\\u1ECDc plan c\\u1EE7a Spark ch\\xFAng ta s\\u1EBD \\u0111\\u1ECDc ng\\u01B0\\u1EE3c, \\u0111\\u1ECDc t\\u1EEB d\\u01B0\\u1EDBi l\\xEAn tr\\xEAn. \\u0110\\u1EA7u ti\\xEAn s\\u1EBD l\\xE0\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"Join 2 dataframe\"}),`\n`,(0,e.jsx)(n.li,{children:\"Filter Salary \u003e= 4000\"}),`\n`,(0,e.jsx)(n.li,{children:\"Project (Select) c\\xE1c c\\u1ED9t \\u0111\\u1ED3ng th\\u1EDDi c\\u1ED9t salary * 3\"}),`\n`,(0,e.jsx)(n.li,{children:\"B\\u01B0\\u1EDBc cu\\u1ED1i c\\xF9ng s\\u1EBD filer l\\u1EA1i nh\\u1EEFng ng\\u01B0\\u1EDDi c\\xF3 t\\xEAn l\\xE0 Duyet ho\\u1EB7c Duong\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"R\\xF5 r\\xE0ng c\\xE1c b\\u01B0\\u1EDBc transform n\\xE0y kh\\xF4ng t\\u1ED1i \\u01B0u. N\\u1EBFu l\\xE0 m\\xECnh s\\u1EBD vi\\u1EBFt 1 c\\xE1ch t\\u1ED1i \\u01B0u h\\u01A1n b\\u1EB1ng c\\xE1ch filter tr\\u01B0\\u1EDBc nh\\u1EEFng \\u0111i\\u1EC1u ki\\u1EC7n c\\xF3 s\\u1EB5n r\\u1ED3i m\\u1EDBi join 2 data sau c\\xF9ng, nh\\u01B0ng \\u0111\\xE2y l\\xE0 v\\xED d\\u1EE5 \\u0111\\u1EC3 th\\u1EA5y \\u0111\\u01B0\\u1EE3c Spark Catalyst s\\u1EBD optimize nh\\u01B0 th\\u1EBF n\\xE0o. M\\xECnh ti\\u1EBFp t\\u1EE5c nh\\xECn xem Optimize Logical Plan sau khi Spark Optimize nh\\xE9.\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-8.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"Sau khi Optimized ch\\xFAng ta th\\u1EA5y c\\xE1c step \\u0111\\xE3 \\u0111\\u01B0\\u1EE3c t\\u1EF1 \\u0111\\u1ED9ng thay \\u0111\\u1ED5i v\\xE0 \\u0111\\u01B0\\u1EE3c g\\u1ED9p l\\u1EA1i chung v\\u1EDBi nhau\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"\\u0110\\u1EA7u ti\\xEAn s\\u1EBD filter df2 c\\u1ED9t dep_id not null\"}),`\n`,(0,e.jsx)(n.li,{children:\"Ti\\u1EBFp theo s\\u1EBD g\\u1ED9p filter Salary \u003e= 4000 v\\xE0 filter firstname v\\xE0 c\\u1ED9t dep_id not null cho df1\"}),`\n`,(0,e.jsx)(n.li,{children:\"Cu\\u1ED1i c\\xF9ng m\\u1EDBi join\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"R\\xF5 r\\xE0ng l\\xE0 \\u0111\\xE3 Optimize h\\u01A1n c\\xE1c b\\u01B0\\u1EDBc Expect behavior.\"}),`\n`,(0,e.jsx)(n.p,{children:\"Tuy nhi\\xEAn m\\xECnh c\\xF3 1 l\\u01B0u \\xFD l\\xE0 Catalyst Optimizer ch\\u1EC9 c\\xF3 DataFrame ho\\u1EB7c DataSet ho\\u1EB7c SQL query m\\u1EDBi c\\xF3 th\\u1EC3 ch\\u1EA1y qua 1 s\\u1ED1 Spark Feature nh\\u01B0 Catalyst Optimizer ho\\u1EB7c Tungsten Optimizer. N\\u1EBFu c\\xE1c b\\u1EA1n s\\u1EED d\\u1EE5ng RDD \\u0111\\u1EC3 process c\\xE1c b\\u1EA1n ph\\u1EA3i t\\u1EF1 t\\u1ED1i \\u01B0u.\"}),`\n`,(0,e.jsxs)(n.p,{children:[\"Sau khi c\\xF3 Optimize Logical plan, \\u1EDF Physical planning Spark s\\u1EBD generate ra nhi\\u1EC1u physical plan. Cost model s\\u1EBD t\\xEDnh cost c\\u1EE7a t\\u1EEBng Physical plan sao cho t\\u1ED1i \\u01B0u nh\\u1EA5t v\\xE0 ch\\u1ECDn n\\xF3, Ngo\\xE0i ra \",(0,e.jsx)(n.strong,{children:\"Cost-base optimization\"}),\" s\\u1EBD ch\\u1ECDn c\\xE1ch join sao cho ph\\xF9 h\\u1EE3p nh\\u1EA5t v\\u1EDBi data.\"]}),`\n`,(0,e.jsx)(n.h3,{children:\"Physical plan\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.img,{src:\"/media/2022/07/spark-behind-9.png\",alt:\"\"})}),`\n`,(0,e.jsx)(n.p,{children:\"\\u1EDE physcal plan s\\u1EBD c\\xF3 2 b\\u01B0\\u1EDBc:\"}),`\n`,(0,e.jsx)(n.p,{children:\"B\\u01B0\\u1EDBc 1:\"}),`\n`,(0,e.jsx)(n.p,{children:\"T\\u1EA1o ra nh\\u1EEFng step s\\u1EED d\\u1EE5ng c\\xE1c strategies \\u1EE9ng v\\u1EDBi m\\u1ED7i node c\\u1EE7a logical plan, v\\xED d\\u1EE5:\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"Trong logical plan: JOIN\"}),`\n`,(0,e.jsx)(n.li,{children:\"Trong Physical plan: SortMergeJoin, BroadcastHashJoin\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"B\\u01B0\\u1EDBc 2:\"}),`\n`,(0,e.jsx)(n.p,{children:\"Final version plan s\\u1EBD \\u0111\\u01B0\\u1EE3c th\\u1EF1c hi\\u1EC7n, t\\u1EA1o ra RDD code\"}),`\n`,(0,e.jsx)(n.h4,{children:\"Operator\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"FileScan: mi\\xEAu t\\u1EA3 vi\\u1EC7c \\u0111\\u1ECDc data t\\u1EEB 1 format.\"}),`\n`,(0,e.jsx)(n.li,{children:\"Exchange: mi\\xEAu t\\u1EA3 vi\\u1EC7c shuffle - physical data movement tr\\xEAn cluster.\"}),`\n`,(0,e.jsx)(n.li,{children:\"HashAggregate, SortAggregate, ObjectHashAggregate: Mi\\xEAu t\\u1EA3 data aggregation.\"}),`\n`,(0,e.jsx)(n.li,{children:\"SortMergeJoin: Mi\\xEAu t\\u1EA3 vi\\u1EC7c join 2 dataframe, Exchange v\\xE0 sort th\\u01B0\\u1EDDng s\\u1EBD x\\u1EA3y ra tr\\u01B0\\u1EDBc khi SortMergeJoin nh\\u01B0ng kh\\xF4ng nh\\u1EA5t thi\\u1EBFt ph\\u1EA3i x\\u1EA3y ra.\"}),`\n`,(0,e.jsx)(n.li,{children:\"BroadcastHashJoin: Mi\\xEAu t\\u1EA3 vi\\u1EC7c join 2 dataframe.\"}),`\n`]}),`\n`,(0,e.jsx)(n.h4,{children:\"Additional Rules\"}),`\n`,(0,e.jsx)(n.p,{children:\"Ngo\\xE0i Operator c\\xF2n c\\xF3 nh\\u1EEFng rule nh\\u01B0:\"}),`\n`,(0,e.jsxs)(n.ul,{children:[`\n`,(0,e.jsx)(n.li,{children:\"EnsureRequirements\"}),`\n`,(0,e.jsx)(n.li,{children:\"ReuseExchange\"}),`\n`,(0,e.jsx)(n.li,{children:\"\\u2026\"}),`\n`]}),`\n`,(0,e.jsx)(n.p,{children:\"Sau khi ch\\u1ECDn ra \\u0111\\u01B0\\u1EE3c Physical plan ph\\xF9 h\\u1EE3p. Code generator s\\u1EBD generate Java code Binary v\\xE0 s\\u1EBD \\u0111\\u01B0\\u1EE3c th\\u1EF1 hi\\u1EC7n tr\\xEAn c\\xE1c worker.\"}),`\n`,(0,e.jsx)(n.h2,{children:\"Executor\"}),`\n`,(0,e.jsx)(n.p,{children:\"Spark app th\\u01B0\\u1EDDng s\\u1EBD start 1 ho\\u1EB7c nhi\\u1EC1u Executor \\u0111\\u1EC3 th\\u1EF1c hi\\u1EC7n task.\"}),`\n`,(0,e.jsx)(n.p,{children:\"M\\u1EB7c \\u0111\\u1ECBnh (Static Allocation of Executors) v\\u1EDBi ch\\u1EBF \\u0111\\u1ED9 n\\xE0y Executor th\\u01B0\\u1EDDng s\\u1EBD ch\\u1EA1y cho t\\u1EDBi khi n\\xE0o Spark app k\\u1EBFt th\\xFAc. Vi\\u1EC7c n\\xE0y d\\u1EABn \\u0111\\u1EBFn kh\\xF4ng t\\u1ED1i \\u01B0u v\\u1EC1 resource\"}),`\n`,(0,e.jsx)(n.p,{children:\"Kh\\xE1c v\\u1EDBi static (Dynamic Allocation). c\\xE1c Executor s\\u1EBD t\\u1EF1 \\u0111\\u1ED9ng remove khi th\\u1EF1c hi\\u1EC7n xong task. Vi\\u1EC7c n\\xE0y s\\u1EBD ti\\u1EBFt ki\\u1EC7m resource cho cluster.\"}),`\n`,(0,e.jsx)(n.p,{children:\"Ngo\\xE0i ra Executor report hearbeat v\\xE0 c\\xE1c metrics c\\u1EE7a task v\\u1EC1 cho driver.\"}),`\n`,(0,e.jsx)(n.p,{children:\"Executor c\\xF3 th\\u1EC3 run multiple task song song v\\xE0 tu\\u1EA7n t\\u1EF1, v\\xE0 tracking nh\\u1EEFng task \\u0111ang ch\\u1EA1y.\"}),`\n`,(0,e.jsx)(n.h1,{children:\"References\"}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://github.com/JerryLead/SparkInternals\",children:\"https://github.com/JerryLead/SparkInternals\"})}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://www.slideshare.net/databricks/physical-plans-in-spark-sql\",children:\"https://www.slideshare.net/databricks/physical-plans-in-spark-sql\"})}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html\",children:\"https://databricks.com/blog/2015/04/13/deep-dive-into-spark-sqls-catalyst-optimizer.html\"})}),`\n`,(0,e.jsx)(n.p,{children:(0,e.jsx)(n.a,{href:\"https://books.japila.pl/apache-spark-internals/\",children:\"https://books.japila.pl/apache-spark-internals/\"})}),`\n`,(0,e.jsx)(n.p,{children:\"Spark Submit Conference\"})]})}function f(i={}){let{wrapper:n}=i.components||{};return n?(0,e.jsx)(n,Object.assign({},i,{children:(0,e.jsx)(d,i)})):d(i)}var D=f;return S(x);})();\n;return Component;","toc":[],"frontMatter":{"readingTime":{"text":"11 min read","minutes":10.46,"time":627600,"words":2092},"slug":"apache-spark-behind-the-scienes","fileName":"2022-07-12-apache-spark-behind-the-scienes.md","title":"Apache Spark behind the scenes","authors":["hung"],"date":"2022-07-12T00:00:00.000Z","tags":["engineering","data"],"summary":"Các bạn có thắc mắc sau khi submit 1 job cho Spark Cluster thì Spark sẽ làm những gì không? Cùng tìm hiểu với mình nhé.","layout":"PostLayout"}},"authorDetails":[{"readingTime":{"text":"1 min read","minutes":0.175,"time":10500,"words":35},"slug":["hung"],"fileName":"hung.md","name":"Hung Tran","avatar":"https://avatars.githubusercontent.com/u/61528065?v=4","occupation":"Data Engineer","company":"Fossil Vietnam","email":"tghung@fossil.com","linkedin":"https://www.linkedin.com/in/hungtran97","github":"https://github.com/hungtran150","date":null}],"prev":{"title":"Working From Home","authors":["phuong"],"date":"2022-07-11T00:00:00.000Z","tags":["management"],"summary":"Working From Home hiện đang là working style trending, nhưng liệu có hiệu quả?","layout":"PostLayout","slug":"working-from-home"},"next":null},"__N_SSG":true},"page":"/blog/[...slug]","query":{"slug":["apache-spark-behind-the-scienes"]},"buildId":"_xuPiwf0iXmMr_jdV40M4","isFallback":false,"gsp":true,"scriptLoader":[]}</script></body></html>